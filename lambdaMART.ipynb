{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: LambdaMART Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import bcolz\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(text):\n",
    "    '''\n",
    "    Function that normalises text and returns tokens.\n",
    "    Input: text --> text string we want to tokenise\n",
    "    Output: tokens --> list of tokens taken from the text string\n",
    "    '''\n",
    "\n",
    "    text = text.lower() # convert all to lower case\n",
    "    text = contractions.fix(text) # expand contractions\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))) # remove punctuation\n",
    "    tokens = text.split() # tokenisation\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_words] # remove stop words\n",
    "    # filtered_tokens = list(map(lemmatizer.lemmatize, filtered_tokens)) # lemmatization of nouns\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in pickled embeddings\n",
    "vectors = bcolz.open('6B.50.dat')[:]\n",
    "words = pickle.load(open('6B.50_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open('6B.50_idx.pkl', 'rb'))\n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import BM25 and TF-IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_train = pd.read_csv('bm25_train.csv', delimiter=',', header=None, names=['qid','pid','bm25'])\n",
    "tfidf_train = pd.read_csv('tfidf_train.csv', delimiter=',', header=None, names=['qid','pid','tfidf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_val = pd.read_csv('bm25_val.csv', delimiter=',', header=None, names=['qid','pid','bm25'])\n",
    "tfidf_val = pd.read_csv('tfidf_val.csv', delimiter=',', header=None, names=['qid','pid','tfidf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = pd.read_csv('train_data.tsv', delimiter='\\t')\n",
    "train_dataframe = train_dataframe.join(bm25_train['bm25'])\n",
    "train_dataframe = train_dataframe.join(tfidf_train['tfidf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataframe = pd.read_csv('validation_data.tsv', delimiter='\\t')\n",
    "val_dataframe = val_dataframe.join(bm25_val['bm25'])\n",
    "val_dataframe = val_dataframe.join(tfidf_val['tfidf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_train = []\n",
    "y_data_train = []\n",
    "\n",
    "def train_data_extraction(row):\n",
    "\n",
    "    q_embed = np.zeros(50) # we chose glove vectors to have length = 50\n",
    "    p_embed = np.zeros(50)\n",
    "    \n",
    "    query = normalise(row['queries'])\n",
    "    for q in query:\n",
    "        try:\n",
    "            q_embed += glove[q]\n",
    "        except:\n",
    "            q_embed += glove['<unk>'] # if the token is not present in GloVe, we assign it as <unk>\n",
    "    q_embed /= len(query)\n",
    "\n",
    "    passage = normalise(row['passage'])\n",
    "    for p in passage:\n",
    "        try:\n",
    "            p_embed += glove[p]\n",
    "        except:\n",
    "            p_embed += glove['<unk>'] # if the token is not present in GloVe, we assign it as <unk>\n",
    "    p_embed /= len(passage)\n",
    "\n",
    "    rel = row['relevancy']\n",
    "    \n",
    "    sim = dot(q_embed, p_embed) / (norm(q_embed) * norm(p_embed))\n",
    "    bm25_score = row['bm25']\n",
    "    tfidf_score = row['tfidf']\n",
    "    q_len = len(query)\n",
    "    p_len = len(passage)\n",
    "\n",
    "    X_data_train.append([sim, bm25_score, tfidf_score, q_len, p_len])\n",
    "    y_data_train.append(rel)\n",
    "\n",
    "_ = train_dataframe.apply(lambda row: train_data_extraction(row), axis=1)\n",
    "\n",
    "X_data_train = np.array(X_data_train, dtype=\"O\")\n",
    "y_data_train = np.array(y_data_train, dtype=\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed training data to use in NN model in Task 4\n",
    "np.savetxt('processed_X_train_data.txt', X_data_train, fmt='%f')\n",
    "np.savetxt('processed_y_train_data.txt', y_data_train, fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_val = []\n",
    "y_data_val = []\n",
    "\n",
    "def val_data_extraction(row):\n",
    "\n",
    "    q_embed = np.zeros(50) # we chose glove vectors to have length = 50\n",
    "    p_embed = np.zeros(50)\n",
    "    \n",
    "    query = normalise(row['queries'])\n",
    "    for q in query:\n",
    "        try:\n",
    "            q_embed += glove[q]\n",
    "        except:\n",
    "            q_embed += glove['<unk>'] # if the token is not present in GloVe, we assign it as <unk>\n",
    "    q_embed /= len(query)\n",
    "\n",
    "    passage = normalise(row['passage'])\n",
    "    for p in passage:\n",
    "        try:\n",
    "            p_embed += glove[p]\n",
    "        except:\n",
    "            p_embed += glove['<unk>'] # if the token is not present in GloVe, we assign it as <unk>\n",
    "    p_embed /= len(passage)\n",
    "\n",
    "    rel = row['relevancy']\n",
    "    \n",
    "    sim = dot(q_embed, p_embed) / (norm(q_embed) * norm(p_embed))\n",
    "    bm25_score = row['bm25']\n",
    "    tfidf_score = row['tfidf']\n",
    "    q_len = len(query)\n",
    "    p_len = len(passage)\n",
    "\n",
    "    X_data_val.append([sim, bm25_score, tfidf_score, q_len, p_len])\n",
    "    y_data_val.append(rel)\n",
    "\n",
    "_ = val_dataframe.apply(lambda row: val_data_extraction(row), axis=1)\n",
    "\n",
    "X_data_val = np.array(X_data_val, dtype=\"O\")\n",
    "y_data_val = np.array(y_data_val, dtype=\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed validation data to use in NN model in Task 4\n",
    "np.savetxt('processed_X_val_data.txt', X_data_val, fmt='%f')\n",
    "np.savetxt('processed_y_val_data.txt', y_data_val, fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_pid = []\n",
    "\n",
    "def get_qid_pid(row):\n",
    "\n",
    "    qid = row['qid']\n",
    "    pid = row['pid']\n",
    "\n",
    "    qid_pid.append([qid,pid])\n",
    "\n",
    "_ = train_dataframe.apply(lambda row: get_qid_pid(row), axis=1)\n",
    "\n",
    "qid_pid = np.array(qid_pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the qid pid references in the array, so that when we do the tune split, we keep them and we can caluclate the ndcg scores\n",
    "y_data_train = np.concatenate((np.array([y_data_train]).T,qid_pid),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LambdaMART model\n",
    "\n",
    "For LambdaMART we set objective to rank:pairwise, rank:ndcg, or rank:map.\n",
    "\n",
    "Here we parameterise the model and we do hyperparameter tuning to derive the best performing model.\n",
    "\n",
    "Main hyperparameters to focus on:\n",
    "\n",
    "Control overfitting with model complexity:\n",
    "\n",
    "- max_depth (maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit. 0 indicates no limit on depth --> default = 6, range from 0 to +infinity)\n",
    "- min_child_weight (Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, then the building process will give up further partitioning. In linear regression task, this simply corresponds to minimum number of instances needed to be in each node. The larger min_child_weight is, the more conservative the algorithm will be --> default = 1, range from 0 to +infinity)\n",
    "- gamma (minimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be --> detault = 0, rages from 0 to +infinity)\n",
    "- Regularisation with lambda (L2 regularization term on weights. Increasing this value will make model more conservative --> default = 1)\n",
    "- Regularisation with alpha (L1 regularization term on weights. Increasing this value will make model more conservative --> default = 0)\n",
    "\n",
    "Control overfitting by adding randomness:\n",
    "\n",
    "- subsample (Subsample ratio of the training instances. Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. and this will prevent overfitting. Subsampling will occur once in every boosting iteration --> default = 1, range (0,1])\n",
    "- colsample_bytree\n",
    "- Reduce stepsize (eta --> default = 0.3, ranges from 0 to 1) and increase num_round (number of rounds for boosting)\n",
    "\n",
    "For faster training performance:\n",
    "\n",
    "- Set tree_method (default = auto) to hist or gpu_hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Prepare data for training and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training data 90% training, 10% for testing (hyperparameter tuning)\n",
    "X_train, X_tune, yplus_train, yplus_tune = train_test_split(X_data_train,y_data_train,test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = yplus_train[:,0]\n",
    "# qid_pid_train = yplus_train[:,1:] # not necessary\n",
    "\n",
    "y_tune = yplus_tune[:,0]\n",
    "qid_pid_tune = yplus_tune[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DMatrix\n",
    "train_data = xgb.DMatrix(X_train, label=y_train)\n",
    "tune_data = xgb.DMatrix(X_tune, label=y_tune)\n",
    "val_data = xgb.DMatrix(X_data_val, label=y_data_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) mNDCG calculator function for tuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDCG function\n",
    "def mNDCG_tune(ranking, relevancies, k):\n",
    "    '''\n",
    "    Function that computes the Normalized Discounted Cumulative Gain (NDCG) metric for each query in 'queries', \n",
    "    based on a ranking determined by a retrieval model, where queries are matched with passages from most relevant \n",
    "    to least relevant, and based on relevancies between queries and passages.\n",
    "\n",
    "    Inputs:\n",
    "    ranking = array of (qid,pid,score)\n",
    "    relevancies = array of relevancies between each possible (qid,pid) pair\n",
    "    k = top k passages you want to take into account when calculating the AP metric\n",
    "\n",
    "    Outputs:\n",
    "    NDCGs = list of NDCG@k metric for each query, in the same order of appearance as the input list 'queries'\n",
    "    mNDCG = mean NDCG@k of all the queries\n",
    "    '''\n",
    "\n",
    "    queries = np.unique(ranking[:,0])\n",
    "\n",
    "    NDCGs = []\n",
    "\n",
    "    for q in queries:\n",
    "        relevant_pairs = ranking[ranking[:,0]==q]\n",
    "        relevant_rels = relevancies[ranking[:,0]==q]\n",
    "        indxs = np.argsort(relevant_pairs[:,2])[::-1]\n",
    "        rel_ranking = relevant_rels[indxs]\n",
    "        ideal_ranking = np.sort(rel_ranking)[::-1]\n",
    "\n",
    "        DCG = 0\n",
    "        IDCG = 0\n",
    "\n",
    "        max_k = len(relevant_rels)\n",
    "        iter = min(k,max_k) # This is because we some queries do not have that many candidate passages\n",
    "\n",
    "        for i in range(1,iter+1):\n",
    "            IDCG += (2**ideal_ranking[i-1] - 1)/np.log2(i+1)\n",
    "            DCG += (2**rel_ranking[i-1] - 1)/np.log2(i+1)\n",
    "\n",
    "        if IDCG != 0:\n",
    "            NDCGs.append(DCG/IDCG)\n",
    "        else: # we do this to avoid the computing error of dividing 0/0\n",
    "            NDCGs.append(0)\n",
    "\n",
    "    mNDCG = np.mean(NDCGs)\n",
    "\n",
    "    return mNDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Hyperparameter tuning\n",
    "The optimal way to do it would be with a massive grid search with all the parameters, but we do not have time nor computing power for that, so we focus in the most imoprtant parameters that have the most effect on a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters of the model\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6, # try values: 8 to 11\n",
    "    'min_child_weight': 1, # try values 4 to 7\n",
    "    'eta':0.3, # try values [.3, .2, .1, .05, .01, .005]\n",
    "    # 'num_round':10, # try values [10, 20, 30, .50, .100, .300]\n",
    "    'subsample': 1, # try values [0.7, 0.8, 0.9, 1] - proportion of data samples we use\n",
    "    'colsample_bytree': 1, # try values [0.7, 0.8, 0.9, 1] - proportion of features we use\n",
    "    # Other parameters\n",
    "    'objective':'rank:pairwise',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1) max_depth vs min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [8,9,10,11]\n",
    "min_child_weights = [4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mNDCGs = np.zeros([len(max_depths), len(min_child_weights)])\n",
    "\n",
    "for i in range(len(max_depths)):\n",
    "    for j in range(len(min_child_weights)):\n",
    "        \n",
    "        params = {'max_depth':max_depths[i], 'min_child_weight': min_child_weights[j], 'eta':0.3, \n",
    "                    'subsample': 1, 'colsample_bytree': 1, 'objective':'rank:pairwise'}\n",
    "        \n",
    "        # Train model with chosen parameters\n",
    "        model = xgb.train(params, train_data)\n",
    "\n",
    "        # Make predictions with the trained model\n",
    "        preds = model.predict(tune_data)\n",
    "\n",
    "        # Get true labels trom tuning data\n",
    "        tuning_labels = tune_data.get_label()\n",
    "\n",
    "        # Evaluate predictions: compute mNDCG of tuning data\n",
    "        # Note that for the NDCG function we put preds as the score in the ranking array, and tuning_labels are the relevancies\n",
    "        ranking_array = np.concatenate((qid_pid_tune,np.array([preds]).T), axis=1)\n",
    "        mNDCGs[i,j] = mNDCG_tune(ranking_array, tuning_labels, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.argwhere(mNDCGs == np.min(mNDCGs))\n",
    "best_max_depth = max_depths[coords[0,0]]\n",
    "best_min_child_weight = min_child_weights[coords[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(best_max_depth)\n",
    "print(best_min_child_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2) subsample vs colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples = [0.7,0.8,0.9,1]\n",
    "colsample_bytrees = [0.7,0.8,0.9,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mNDCGs = np.zeros([len(subsamples), len(colsample_bytrees)])\n",
    "\n",
    "for i in range(len(subsamples)):\n",
    "    for j in range(len(colsample_bytrees)):\n",
    "        \n",
    "        params = {'max_depth':best_max_depth, 'min_child_weight': best_min_child_weight, 'eta':0.3, \n",
    "                    'subsample': subsamples[i], 'colsample_bytree': colsample_bytrees[j], 'objective':'rank:pairwise'}\n",
    "        \n",
    "        # Train model with chosen parameters\n",
    "        model = xgb.train(params, train_data)\n",
    "\n",
    "        # Make predictions with the trained model\n",
    "        preds = model.predict(tune_data)\n",
    "\n",
    "        # Get true labels trom tuning data\n",
    "        tuning_labels = tune_data.get_label()\n",
    "\n",
    "        # Evaluate predictions: compute mNDCG of tuning data\n",
    "        # Note that for the NDCG function we put preds as the score in the ranking array, and tuning_labels are the relevancies\n",
    "        ranking_array = np.concatenate((qid_pid_tune,np.array([preds]).T), axis=1)\n",
    "        mNDCGs[i,j] = mNDCG_tune(ranking_array, tuning_labels, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.argwhere(mNDCGs == np.min(mNDCGs))\n",
    "best_subsample = subsamples[int(coords[0,0])]\n",
    "best_colsample_bytree = colsample_bytrees[int(coords[0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "print(best_subsample)\n",
    "print(best_colsample_bytree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3) eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas = [.3, .2, .1, .05, .01, .005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mNDCGs = np.zeros(len(etas))\n",
    "\n",
    "for i in range(len(etas)):\n",
    "        \n",
    "    params = {'max_depth':best_max_depth, 'min_child_weight': best_min_child_weight, 'eta':etas[i], \n",
    "                'subsample': best_subsample, 'colsample_bytree': best_colsample_bytree, 'objective':'rank:pairwise'}\n",
    "    \n",
    "    # Train model with chosen parameters\n",
    "    model = xgb.train(params, train_data)\n",
    "\n",
    "    # Make predictions with the trained model\n",
    "    preds = model.predict(tune_data)\n",
    "\n",
    "    # Get true labels trom tuning data\n",
    "    tuning_labels = tune_data.get_label()\n",
    "\n",
    "    # Evaluate predictions: compute mNDCG of tuning data\n",
    "    # Note that for the NDCG function we put preds as the score in the ranking array, and tuning_labels are the relevancies\n",
    "    ranking_array = np.concatenate((qid_pid_tune,np.array([preds]).T), axis=1)\n",
    "    mNDCGs[i] = mNDCG_tune(ranking_array, tuning_labels, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.argmin(mNDCGs)\n",
    "best_eta = etas[int(coords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005\n"
     ]
    }
   ],
   "source": [
    "print(best_eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Train final model and get validation ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final parameters\n",
    "params = {'max_depth':11, 'min_child_weight': 7, 'eta':0.005, \n",
    "                'subsample': 0.7, 'colsample_bytree': 0.7, 'objective':'rank:pairwise'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tain model on the full training set\n",
    "train_data = xgb.DMatrix(X_data_train, label=y_data_train[:,0])\n",
    "model = xgb.train(params, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIkAAAR8CAYAAAAZ7cTyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABCvUlEQVR4nO3deZxddZ3n//cHIrSIgBCCYCEYAwIBLBaV/rUiGQUxLWi3jhodYgjIADLoQ3HpRmfQcWy0Q9sOYuOCAgoBRlqCGhDFRLQVZHVhDd0BIQkgyJaAhuX7+6Mu1UU2Cry3KiTP5+NxHrn33OV8D3wft1KvnHNutdYCAAAAwNptndEeAAAAAACjTyQCAAAAQCQCAAAAQCQCAAAAICIRAAAAABGJAAAAAIhIBACwSlX191X1tdEeBwBAr1VrbbTHAACsoarqliRbJHlsyOrtW2sL/8z3PLS19qM/b3TPPlV1XJIJrbX/NtpjAQDWPI4kAgB67YDW2oZDlmcciLqhqsaM5vafqWfruAGAZw+RCAAYcVW1cVWdUlWLqmpBVX26qtbtPPbSqvpxVd1TVXdX1RlVtUnnsW8meXGS71bV4qr6SFXtU1W3L/P+t1TV6zu3j6uqb1fVt6rqgSTTVrX9FYz1uKr6Vuf2tlXVqurgqrqtqu6tqsOr6hVV9euquq+qvjjktdOq6t+q6otVdX9V3VBVrxvy+FZVdX5V/aGqbq6q9y6z3aHjPjzJ3yd5R2fff9V53sFVdX1VPVhV/1FV/33Ie+xTVbdX1Yeq6q7O/h485PHnVtUJVXVrZ3w/q6rndh7bq6p+3tmnX1XVPs/gfzUA8CwiEgEAo+HUJI8mmZBktyT7JTm081gl+YckWyXZMcnWSY5LktbaQUl+l/88Oulzw9zem5N8O8kmSc54iu0Px6uSbJfkHUn+OcmxSV6fZGKSt1fVa5d57r8nGZvkfyX516ratPPYWUlu7+zr25J8pqr+y0rGfUqSzyQ5u7PvL+88564kb0qyUZKDk3y+qnYf8h4vTLJxkhclOSTJSVX1gs5jM5LskeT/S7Jpko8kebyqXpTk+0k+3Vl/TJJzq2rzp/HfCAB4lhGJAIBeO69zNMp9VXVeVW2RZHKSD7TWlrTW7kry+STvTJLW2s2ttR+21v7UWvt9kn9K8tqVv/2w/KK1dl5r7fEMxJSVbn+Y/ndr7Y+ttYuSLEkys7V2V2ttQZKfZiA8PeGuJP/cWnuktXZ2khuT/HVVbZ3kr5J8tPNe1yT5WpKpKxp3a+3hFQ2ktfb91tq/twE/SXJRktcMecojST7V2f7sJIuTvKyq1kkyPcn7W2sLWmuPtdZ+3lr7U5L/lmR2a212Z9s/THJF578bALCGcm47ANBrbxl6kemqemWS5yRZVFVPrF4nyW2dx7dI8oUMhI7ndx67988cw21Dbm+zqu0P051Dbj+8gvsbDrm/oD35m0JuzcCRQ1sl+UNr7cFlHttzJeNeoap6YwaOUNo+A/uxQZLfDHnKPa21R4fcf6gzvrFJ/iIDRzkta5sk/7WqDhiy7jlJ5jzVeACAZy+RCAAYabcl+VOSscvEiyd8JklLsktr7Q9V9ZYkXxzy+LJfzbokA2EkSdK5ttCyp0UNfc1Tbb/bXlRVNSQUvTjJ+UkWJtm0qp4/JBS9OMmCIa9ddl+fdL+q1k9ybgaOPprVWnukqs7LwCl7T+XuJH9M8tIkv1rmsduSfLO19t7lXgUArLGcbgYAjKjW2qIMnBJ1QlVtVFXrdC5W/cQpZc/PwClR93eujfPhZd7iziTjh9y/KclfVNVfV9Vzknw8yfp/xva7bVySo6vqOVX1XzNwnaXZrbXbkvw8yT9U1V9U1a4ZuGbQt1bxXncm2bZzqliSrJeBff19kkc7RxXtN5xBdU69+3qSf+pcQHvdqvrLTnj6VpIDquoNnfV/0bkIdt/T330A4NlCJAIARsPUDASO6zJwKtm3k2zZeeyTSXZPcn8GLp78r8u89h+SfLxzjaNjWmv3JzkyA9fzWZCBI4tuz6qtavvddlkGLnJ9d5L/k+RtrbV7Oo9NSbJtBo4q+k6S/zX01LwV+H+dP++pqqs6RyAdneScDOzHuzJwlNJwHZOBU9MuT/KHJJ9Nsk4nYL05A9+m9vsMHFn04fi7IwCs0erJp8gDANAtVTUtyaGttVeP9lgAAJ6Kfw0CAAAAQCQCAAAAwOlmAAAAAMSRRAAAAABEJAIAAAAgyZjRHsDKbLLJJm3ChAmjPQzWEEuWLMnznve80R4GawBziW4yn+gWc4luMp/oFnOJbjGXuuvKK6+8u7W2+YoeW20j0RZbbJErrrhitIfBGmLu3LnZZ599RnsYrAHMJbrJfKJbzCW6yXyiW8wlusVc6q6qunVljzndDAAAAACRCAAAAACRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAAJKMGe0BrNRDDyVVoz0K1hQzZiSTJo32KFgTmEt0k/lEt5hLdJP5RLeYSyRJa6M9Ap4GRxIBAAAAIBIBAAAAIBIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAQA9Nnz4948aNy8477zy47h3veEf6+/vT39+fbbfdNv39/UmSH/7wh9ljjz2yyy67ZI899siPf/zjwddceeWV2WWXXTJhwoQcffTRaa0tt63WWo4++uhMmDAhu+66a6666qqe79+apKeRqKqOrqrrq+qMqvq/VXVzVf26qnbv5XYBAACA1cO0adNy4YUXPmnd2WefnWuuuSbXXHNN3vrWt+Zv//ZvkyRjx47Nd7/73fzmN7/JaaedloMOOmjwNUcccUS++tWvZt68eZk3b95y75kkF1xwweDjX/nKV3LEEUf0dufWML0+kujIJPsmOSPJdp3lsCT/0uPtAgAAAKuBvffeO5tuuukKH2ut5ZxzzsmUKVOSJLvttlu22mqrJMnEiRPz8MMPZ+nSpVm0aFEeeOCB7LXXXqmqTJ06Needd95y7zdr1qxMnTo1VZW99tor9913XxYtWtSzfVvT9CwSVdXJScYnuSDJd5Kc3gZcmmSTqtqyV9sGAAAAVn8//elPs8UWW2S77bZb7rFzzz03u+++e9Zbb70sWLAgfX19g4/19fVlwYIFy71mwYIF2XrrrZ/yeaxYzyJRa+3wJAuTTErywyS3DXn49iQv6tW2AQAAgNXfzJkzB48iGuraa6/NRz/60Xz5y18ehVGtvcaM9gCGqqrDMnA6WjYfOzZzZ8wY5RGxpljc12c+0RXmEt1kPtEt5hLdZD7RLeYSSZK5c5Mkd9xxR5YsWZK5nftJ8thjj+Xss8/Ol7/85Set//3vf58PfvCD+chHPpLbbrstixcvzj333JObbrpp8HkXX3xxqupJr0uSqsoPfvCDPProo0mSefPm5dZbb83ixYt7uJNrkNZaz5YktyQZm+TLSaYMWX9jki1X9drt+/paSyyWrixzZswY9TFY1ozFXLJ0czGfLN1azCVLNxfzydKtxVyytKQ9Yf78+W3ixIltqAsuuKDtvffeT1p37733tl133bWde+65g+vmzJnTWmvtFa94RfvFL37RHn/88bb//vu373//+21Z3/ve99r+++/fHn/88faLX/yiveIVr1juOWu7JFe0tuIW0+sLVz/h/CRTa8BeSe5vrblyFAAAAKzhpkyZkr/8y7/MjTfemL6+vpxyyilJkrPOOmu5U82++MUv5uabb86nPvWp9Pf3p7+/P/fee2+S5Etf+lIOPfTQTJgwIS996Uvzxje+MUly8skn5+STT06STJ48OePHj8+ECRPy3ve+N1/60pdGcE+f/UbqdLPZSSYnuTnJQ0kOHqHtAgAAAKNo5syZK1x/6qmnLrfu4x//eD7+8Y8/ad0Tp5Ttueee+e1vf7vcaw4//PDB21WVk0466ZkPdi3X00jUWtt2yN339XJbAAAAADxzI3W6GQAAAACrMZEIAAAAAJEIAAAAAJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAACQZM9oDWKkNNkhaG+1RsKaYO9d8ojvMJbrJfKJbzCW6yXyiW8wleNZxJBEAAAAAIhEAAAAAIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAIAkY0Z7ACv10ENJ1WiPgjXFjBnJpEmjPQrWBOYS3WQ+0S3mEt1kPtEt5tKar7XRHgFd5kgiAAAAAEQiAAAAAEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAMCfYfr06Rk3blx23nnnwXXveMc70t/fn/7+/my77bbp7+8ffOwf/uEfMmHChLzsZS/LD37wg8H19913X972trdlhx12yI477phf/OIXy22rtZajjz46EyZMyK677pqrrrqqp/u2thnTqzeuqqOTHJFkhyS/SVJJHkxyRGvtV73aLgAAADBypk2blqOOOipTp04dXHf22WcP3v7Qhz6UjTfeOEly3XXX5ayzzsq1116bhQsX5vWvf31uuummrLvuunn/+9+f/fffP9/+9rezdOnSPPTQQ8tt64ILLsi8efMyb968XHbZZTniiCNy2WWX9X4n1xK9PJLoyCT7JvmrJK9tre2S5H8n+UoPtwkAAACMoL333jubbrrpCh9rreWcc87JlClTkiSzZs3KO9/5zqy//vp5yUtekgkTJuSXv/xl7r///lxyySU55JBDkiTrrbdeNtlkk+Xeb9asWZk6dWqqKnvttVfuu+++LFq0qGf7trbpSSSqqpOTjE9yQZJXtdbu7Tx0aZK+XmwTAAAAWL389Kc/zRZbbJHtttsuSbJgwYJsvfXWg4/39fVlwYIFmT9/fjbffPMcfPDB2W233XLooYdmyZIly73fyl5Pd/TkdLPW2uFVtX+SSa21u4c8dEgGwtEKVdVhSQ5Lks3Hjs3cGTN6MTzWQov7+swnusJcopvMJ7rFXKKbzCe6xVxaC8ydO3jzjjvuyJIlSzJ3yLok+fznP59XvvKVg+sXLFiQ66+/fvD+okWLcu211+aee+7JlVdemWnTpmXatGk58cQTc8QRR2T69OlZvHjx4PPvueeeXH311Xn00UeTJPfee2+uvPLKLF68uMc7u5ZorfVkSXJLkrFD7k9Kcn2SzYbz+u37+lpLLJauLHNmzBj1MVjWjMVcsnRzMZ8s3VrMJUs3F/PJ0q3FXFoLliHmz5/fJk6c+KR1jzzySBs3bly77bbbBtd95jOfaZ/5zGcG7++3337t5z//eVu0aFHbZpttBtdfcsklbfLkya211ubMmTO4/rDDDmtnnnnm4P3tt9++LVy4sDF8Sa5obcUtZkS+3ayqdk3ytSRvbq3dMxLbBAAAAEbPj370o+ywww7p6/vPq84ceOCBOeuss/KnP/0p8+fPz7x58/LKV74yL3zhC7P11lvnxhtvTJJcfPHF2WmnnZZ7zwMPPDCnn356Wmu59NJLs/HGG2fLLbccsX1a0/Xs282eUFUvTvKvSQ5qrd3U6+0BAAAAI2fKlCmZO3du7r777vT19eWTn/xkDjnkkJx11lmDF6x+wsSJE/P2t789O+20U8aMGZOTTjop6667bpLkxBNPzLvf/e4sXbo048ePzze+8Y0kyfnnn58bbrghhx9+eCZPnpzZs2dnwoQJ2WCDDQafQ3f0PBIl+Z9JNkvypapKkkdba3uOwHYBAACAHps5c+YK15966qkrXH/sscfm2GOPXW59f39/rrjiiuXWH3jggdlnn32SJFWVk0466RmPlVXrWSRqrW3buXloZwEAAABgNTUi1yQCAAAAYPUmEgEAAAAgEgEAAAAgEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAACQZMxoD2ClNtggaW20R8GaYu5c84nuMJfoJvOJbjGX6CbziW4xl+BZx5FEAAAAAIhEAAAAAIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABAhhmJquqlVbV+5/Y+VXV0VW3S05EBAAAAMGLGDPN55ybZs6omJPlKkllJzkwyuVcDy0MPJVU9e3vWMjNmJJMmjfYoWBOYS3ST+US3mEt0k/lEt5hLz0xroz0C1mLDPd3s8dbao0n+JsmJrbUPJ9myd8MCAAAAYCQNNxI9UlVTkrwnyfc6657TmyEBAAAAMNKGG4kOTvKXSf5Pa21+Vb0kyTd7NywAAAAARtKwrknUWruuqj6a5MWd+/OTfLaXAwMAAABg5Az3280OSHJNkgs79/ur6vwejgsAAACAETTc082OS/LKJPclSWvtmiTjezIiAAAAAEbcsC9c3Vq7f5l1j3d7MAAAAACMjmFdkyjJtVX1riTrVtV2SY5O8vPeDQsAAACAkTTcI4n+R5KJSf6U5Mwk9yf5QI/GBAAAAMAIe8ojiapq3STfb61NSnJs74cEAAAAwEh7yiOJWmuPJXm8qjYegfEAAAAAMAqGe02ixUl+U1U/TLLkiZWttaN7MioAAAAARtRwI9G/dhYAAAAA1kDDunB1a+20FS29HhwAAACsjaZPn55x48Zl5513ftL6E088MTvssEMmTpyYj3zkI0mSX/7yl+nv709/f39e/vKX5zvf+U6S5LbbbsukSZOy0047ZeLEifnCF76wwm211nL00UdnwoQJ2XXXXXPVVVf1dudYbQ3rSKKqmp+kLbu+tTZ+Fa85OskRSa5LslWS3ZMc21qb8cyGCgAAAGuHadOm5aijjsrUqVMH182ZMyezZs3Kr371q6y//vq56667kiQ777xzrrjiiowZMyaLFi3Ky1/+8hxwwAEZM2ZMTjjhhOy+++558MEHs8cee2TffffNTjvt9KRtXXDBBZk3b17mzZuXyy67LEcccUQuu+yyEd1fVg/DPd1szyG3/yLJf02y6VO85sgkr0+yNMk2Sd7ydAcHAAAAa6O99947t9xyy5PW/cu//Es+9rGPZf3110+SjBs3LkmywQYbDD7nj3/8Y6oqSbLllltmyy23TJI8//nPz4477pgFCxYsF4lmzZqVqVOnpqqy11575b777suiRYsGX8vaY7inm90zZFnQWvvnJH+9sudX1clJxie5IMm7W2uXJ3mkGwMGAACAtdFNN92Un/70p3nVq16V1772tbn88ssHH7vssssyceLE7LLLLjn55JMzZsyTjwm55ZZbcvXVV+dVr3rVcu+7YMGCbL311oP3+/r6smDBgt7tCKut4Z5utvuQu+tk4Miilb62tXZ4Ve2fZFJr7e7hDqaqDktyWJJsPnZs5s5wZhrdsbivz3yiK8wlusl8olvMJbrJfKJbzKVnaO7cwZt33HFHlixZkrmddffff39+85vf5Pjjj88NN9yQAw88MGeeeebgkUMnnXRSbr311vz93/99nve852W99dZLkjz88MN5//vfn0MPPXSF1xu65557cvXVV+fRRx9Nktx777258sors3jx4t7u6zAtXrx48L8BPdZae8olyZwhyw+TfCXJy57iNbckGTvk/nFJjhnO9lpr2b6vr7XEYunKMmfGjFEfg2XNWMwlSzcX88nSrcVcsnRzMZ8s3VrMpWe4DDF//vw2ceLEwftveMMb2o9//OPB++PHj2933XVXW9akSZPa5Zdf3lprbenSpW2//fZrJ5xwwnLPe8Jhhx3WzjzzzMH722+/fVu4cOFKnz/S5syZM9pDWKMkuaK1FbeYYZ1uluSQ1tqkzrJva+2wDFxrCAAAABgBb3nLWzJnzpwkA6eeLV26NGPHjs38+fMHjwK69dZbc8MNN2TbbbdNay2HHHJIdtxxx3zwgx9c6fseeOCBOf3009Nay6WXXpqNN97Y9YjWUsO9cPW3M/DtZMuu26O7wwEAAACmTJmSuXPn5u67705fX18++clPZvr06Zk+fXp23nnnrLfeejnttNNSVfnZz36W448/Ps95znOyzjrr5Etf+lLGjh2bn/3sZ/nmN7+ZXXbZJf39/UmSz3zmM5k8eXJOPvnkJMnhhx+eyZMnZ/bs2ZkwYUI22GCDfOMb3xjFPWc0rTISVdUOSSYm2biq/nbIQxtl4FvOnlJVvTDJFZ3XPF5VH0iyU2vtgWc0YgAAAFjDzZw5c4Xrv/Wtby237qCDDspBBx203PpXv/rVGTi7aHmHH3744O2qykknnfQMR8qa5KmOJHpZkjcl2STJAUPWP5jkvat6YWtt2yF3+57B2AAAAAAYIauMRK21WUlmVdVfttZ+MUJjAgAAAGCEDfeaRFdX1fsycOrZ4GlmrbXpPRkVAAAAACNquN9u9s0kL0zyhiQ/ycDpYw/2alAAAAAAjKzhRqIJrbVPJFnSWjstyV8neVXvhgUAAADASBpuJHqk8+d9VbVzko2TjOvNkAAAAAAYacO9JtFXquoFST6R5PwkGyb5nz0bFQAAAAAjaliRqLX2tc7NnyQZ37vhAAAAADAahnW6WVVtUVWnVNUFnfs7VdUhvR0aAAAAACNluNckOjXJD5Js1bl/U5IP9GA8AAAAAIyC4Uaisa21c5I8niSttUeTPNazUQEAAAAwooYbiZZU1WZJWpJU1V5J7u/ZqAAAAAAYUcP9drMPZuBbzV5aVf+WZPMkb+vZqAAAAAAYUauMRFX14tba71prV1XVa5O8LEklubG19khPR7bBBklrPd0Ea5G5c80nusNcopvMJ7rFXKKbzCe6xVyCZ52nOt3svCG3z26tXdta+23PAxEAAAAAI+qpIlENuT2+lwMBAAAAYPQ8VSRqK7kNAAAAwBrkqS5c/fKqeiADRxQ9t3M7nfuttbZRT0cHAAAAwIhYZSRqra07UgMBAAAAYPQ81elmAAAAAKwFRCIAAAAARCIAAAAARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABAkjGjPYCVeuihpGq0R8GaYsaMZNKk0R4FawJziW4yn+gWc4luMp+eudZGewQAfxZHEgEAAAAgEgEAAAAgEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAADomunTp2fcuHHZeeedB9d94hOfyK677pr+/v7st99+WbhwYZLk/vvvzwEHHJCXv/zlmThxYr7xjW886b0eeOCB9PX15aijjlrhtv7whz9k3333zXbbbZd999039957b+92DFgr9DQSVdXRVXV9VZ3Ruf+Kqnq0qt7Wy+0CAACMhmnTpuXCCy980roPf/jD+fWvf51rrrkmb3rTm/KpT30qSXLSSSdlp512yq9+9avMnTs3H/rQh7J06dLB133iE5/I3nvvvdJtHX/88Xnd616XefPm5XWve12OP/743uwUsNbo9ZFERybZt7X27qpaN8lnk1zU420CAACMir333jubbrrpk9ZttNFGg7eXLFmSqkqSVFUefPDBtNayePHibLrpphkzZkyS5Morr8ydd96Z/fbbb6XbmjVrVt7znvckSd7znvfkvPPO6/LeAGubMb1646o6Ocn4JBdU1deTtCTnJnlFr7YJAACwOjr22GNz+umnZ+ONN86cOXOSJEcddVQOPPDAbLXVVnnwwQdz9tlnZ5111snjjz+eD33oQ/nWt76VH/3oRyt9zzvvvDNbbrllkuSFL3xh7rzzzhHZF2DNVa213r151S1J9kyyfpIzk0xK8vUk32utfXsFzz8syWFJsvnYsXuc87GP9WxsrF0W9/Vlw9tvH+1hsAYwl+gm84luMZfoJvPpz7DHHkmSO+64I3/3d3+33DWGkuSMM87I0qVLc/DBB+cnP/lJfvvb3+bII4/MwoULc8wxx+RrX/taLrroovzxj3/MlClTcuGFF+bGG2/M+9///uXe601velO+973vDd4/4IAD8t3vfrd3+/c0LV68OBtuuOFoD4M1gLnUXZMmTbqytbbnCh9srfVsSXJLkrFJ/l+SvTrrTk3ytqd67fZ9fa0lFktXljkzZoz6GCxrxmIuWbq5mE+Wbi3mkqWbi/n0Zywd8+fPbxMnTmwrcuuttw4+Nnny5HbJJZcMPjZp0qR22WWXtXe9611t6623bttss03bbLPN2vOf//z20Y9+dLn32n777dvChQtba60tXLiwbb/99ivc5miZM2fOaA+BNYS51F1JrmhtxS1mpL7dbM8kZ3WOLHpbki9V1VtGaNsAAACjZt68eYO3Z82alR122CFJ8uIXvzgXX3xxkoFTx2688caMHz8+Z5xxRn73u9/llltuyYwZMzJ16tQVXpT6wAMPzGmnnZYkOe200/LmN795BPYGWJP17JpEQ7XWXvLE7ao6NQOnm503EtsGAAAYKVOmTMncuXNz9913p6+vL5/85Ccze/bs3HjjjVlnnXWyzTbb5OSTT04y8O1l06ZNyy677JLWWj772c9m7Nixq3z/Qw89NIcffnj23HPPfOxjH8vb3/72nHLKKdlmm21yzjnnjMQuAmuwEYlEAAAAa4OZM2cut+6QQw5Z4XO32mqrXHTRqr/8edq0aZk2bdrg/a997WuDtzfbbLPBI5EAuqGnkai1tu0K1k3r5TYBAAAAePpG6ppEAAAAAKzGRCIAAAAARCIAAAAARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAkGTMaA9gpTbYIGlttEfBmmLuXPOJ7jCX6CbziW4xl+gm8wlgreVIIgAAAABEIgAAAABEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAIMmY0R7ASj30UFI12qNgTTFjRjJp0miPgmeL1kZ7BAAAACPOkUQAAAAAiEQAAAAAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAFbpsccey2677ZY3velNSZIrr7wyu+++e/r7+/PqV786N998c5Lkd7/7XSZNmpTddtstu+66a2bPnr3C97vwwgvzspe9LBMmTMjxxx8/YvsBAADwVHoaiarq6Kq6vqrurapfV9U1VXVFVb26l9sF6JYvfOEL2XHHHQfv//M//3POOOOMXHPNNXnXu96VT3/600mST3/603n729+eq6++OmeddVaOPPLI5d7rsccey/ve975ccMEFue666zJz5sxcd911I7YvAAAAq9LrI4mOTLJvkq2TvLy11p9kepKv9Xi7AH+222+/Pd///vdz6KGHDq6rqjzwwANJkvvvvz9bbbXVKtcP9ctf/jITJkzI+PHjs9566+Wd73xnZs2aNQJ7AgAA8NTG9OqNq+rkJOOTXJDk6621z3ceel6S1qvtAnTLBz7wgXzuc5/Lgw8+OLjumGOOyeTJk/Pc5z43G220US699NIkyXHHHZf99tsvJ554YpYsWZIf/ehHy73fggULsvXWWw/e7+vry2WXXdb7HQEAABiGnh1J1Fo7PMnCJJNaa5+vqr+pqhuSfD8DRxMBrLa+973vZdy4cdljjz2etP7b3/52Zs+endtvvz0HH3xwPvjBDyZJZs6cmWnTpuX222/P7Nmzc9BBB+Xxxx8fjaEDAAA8I9Va7w7qqapbkuzZWrt7yLq9k/zP1trrV/D8w5IcliSbjx27xzkf+1jPxsbaZXFfXza8/fbRHgbPFnvska9+9au56KKLsu6662bp0qV56KGH0t/fn1tvvTUzZ85Mktx555356Ec/mlNPPTXTpk3L5z73uYwbNy5J8q53vSsnnXRSXvCCFwy+7bXXXptTTz01//iP/5gkOeOMM5Ik7373u0d4B1ldLF68OBtuuOFoD4M1gLlEN5lPdIu5RLeYS901adKkK1tre67osRGPRJ31/5HklcuuH+plW2/dbvRLPV0yd8aM7HPMMaM9DJ4tlvlcnDt3bmbMmJHzzjsvm222WS6//PJsv/32OeWUUzJ79uyce+65eeMb35h3vOMdmTZtWq6//vq87nWvy4IFC1JVg+/z6KOPZvvtt8/FF1+cF73oRXnFK16RM888MxMnThzpPWQ1MXfu3Oyzzz6jPQzWAOYS3WQ+0S3mEt1iLnVXVa00EvXsmkTLDGBCkn9vrbWq2j3J+knuGYltA3TLmDFjcswxx+Stb31r1llnnbzgBS/I17/+9STJCSeckPe+9735/Oc/n6rKqaeemqrKwoULc+ihh2b27NkZM2ZMvvjFL+YNb3hDHnvssUyfPl0gAgAAVhsjEomSvDXJ1Kp6JMnDSd7RenkIE0AX7bPPPoP/cvGa17wmn/jEJ5Z7zk477ZR/+7d/W279VlttldmzZw/enzx5ciZPntyzsQIAADxTPY1ErbVtOzc/21kAAAAAWA317NvNAAAAAHj2EIkAAAAAEIkAAAAAEIkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQJIxoz2Aldpgg6S10R4Fa4q5c80nAAAAWAVHEgEAAAAgEgEAAAAgEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAAAiEgEAAAAQkQgAAACAiEQAAAAARCQCAAAAICIRAAAAABGJAAAAAIhIBAAAAEBEIgAAAACSVGtttMewQlX1YJIbR3scrDHGJrl7tAfBGsFcopvMJ7rFXKKbzCe6xVyiW8yl7tqmtbb5ih4YM9IjeRpubK3tOdqDYM1QVVeYT3SDuUQ3mU90i7lEN5lPdIu5RLeYSyPH6WYAAAAAiEQAAAAArN6R6CujPQDWKOYT3WIu0U3mE91iLtFN5hPdYi7RLebSCFltL1wNAAAAwMhZnY8kAgAAAGCErJaRqKr2r6obq+rmqvrYaI+H1VtVbV1Vc6rquqq6tqre31l/XFUtqKprOsvkIa/5u878urGq3jB6o2d1VFW3VNVvOvPmis66Tavqh1U1r/PnCzrrq6r+b2c+/bqqdh/d0bO6qKqXDfn8uaaqHqiqD/hsYriq6utVdVdV/XbIuqf9WVRV7+k8f15VvWc09oXRtZK59I9VdUNnvnynqjbprN+2qh4e8hl18pDX7NH5+XhzZ77VKOwOo2glc+lp/1zz+x7JSufT2UPm0i1VdU1nvc+mEbLanW5WVesmuSnJvkluT3J5kimttetGdWCstqpqyyRbttauqqrnJ7kyyVuSvD3J4tbajGWev1OSmUlemWSrJD9Ksn1r7bERHTirraq6JcmerbW7h6z7XJI/tNaO7/xl5gWttY92/iL0P5JMTvKqJF9orb1qNMbN6qvzs21BBubIwfHZxDBU1d5JFic5vbW2c2fd0/osqqpNk1yRZM8kLQM/I/dord07CrvEKFnJXNovyY9ba49W1WeTpDOXtk3yvSeet8z7/DLJ0UkuSzI7yf9trV0wQrvBamAlc+m4PI2fa52H/b7HCufTMo+fkOT+1tqnfDaNnNXxSKJXJrm5tfYfrbWlSc5K8uZRHhOrsdbaotbaVZ3bDya5PsmLVvGSNyc5q7X2p9ba/CQ3Z2Dewaq8OclpndunZSBEPrH+9Dbg0iSbdMIlDPW6JP/eWrt1Fc/x2cSTtNYuSfKHZVY/3c+iNyT5YWvtD50w9MMk+/d88KxWVjSXWmsXtdYe7dy9NEnfqt6jM582aq1d2gb+lfn0/Of8Yy2xks+llVnZzzW/75Fk1fOpczTQ2zMQGlfKZ1P3rY6R6EVJbhty//as+hd+GNQpzLtloCInyVGdw6i//sQh+THHeGotyUVVdWVVHdZZt0VrbVHn9h1JtujcNp8YjnfmyX/J8dnEM/V0P4vMK4ZjepKh/+r+kqq6uqp+UlWv6ax7UQbmzxPMJYZ6Oj/XfC4xHK9Jcmdrbd6QdT6bRsDqGIngGamqDZOcm+QDrbUHkvxLkpcm6U+yKMkJozc6nmVe3VrbPckbk7yvcyjsoM6/Uqxe5+qy2qqq9ZIcmOT/dVb5bKIrfBbRDVV1bJJHk5zRWbUoyYtba7sl+WCSM6tqo9EaH88Kfq7RC1Py5H9g89k0QlbHSLQgydZD7vd11sFKVdVzMhCIzmit/WuStNbubK091lp7PMlX85+nbZhjrFJrbUHnz7uSfCcDc+fOJ04j6/x5V+fp5hNP5Y1Jrmqt3Zn4bOLP9nQ/i8wrVqqqpiV5U5J3d6JjOqcG3dO5fWWSf8/AdWQW5MmnpJlLJHlGP9d8LrFKVTUmyd8mOfuJdT6bRs7qGIkuT7JdVb2k86+v70xy/iiPidVY53zVU5Jc31r7pyHrh14X5m+SPHHV/POTvLOq1q+qlyTZLskvR2q8rN6q6nmdC6Cnqp6XZL8MzJ3zkzzxrUDvSTKrc/v8JFNrwF4ZuLjeosB/etK/hPls4s/0dD+LfpBkv6p6QecUkP0661jLVdX+ST6S5MDW2kND1m/eudh+qmp8Bj6L/qMznx6oqr06f/eamv+cf6zFnsHPNb/v8VRen+SG1trgaWQ+m0bOmNEewLI637BwVAb+ArNukq+31q4d5WGxevurJAcl+c0TX5GY5O+TTKmq/gwcin9Lkv+eJK21a6vqnCTXZeDw6vf59iCG2CLJdzrfnDkmyZmttQur6vIk51TVIUluzcCF9JKBb1CYnIGLMT6UgW+ugiSDoXHfdD5/Oj7ns4nhqKqZSfZJMraqbk/yv5Icn6fxWdRa+0NV/e8M/FKWJJ9qrQ33orOsIVYyl/4uyfpJftj5mXdpa+3wJHsn+VRVPZLk8SSHD5kzRyY5NclzM3ANI98etJZZyVza5+n+XPP7HsmK51Nr7ZQsfy3HxGfTiKnOkaUAAAAArMVWx9PNAAAAABhhIhEAAAAAIhEAAAAAIhEAAAAAEYkAAAAAyMDXOwMArLWq6rEkvxmy6i2ttVtGaTgAAKOmWmujPQYAgFFTVYtbaxuO4PbGtNYeHantAQAMl9PNAABWoaq2rKpLquqaqvptVb2ms37/qrqqqn5VVRd31m1aVedV1a+r6tKq2rWz/riq+mZV/VuSb1bV5lV1blVd3ln+ahR3EQAgidPNAACeW1XXdG7Pb639zTKPvyvJD1pr/6eq1k2yQVVtnuSrSfZurc2vqk07z/1kkqtba2+pqv+S5PQk/Z3Hdkry6tbaw1V1ZpLPt9Z+VlUvTvKDJDv2bA8BAIZBJAIA1nYPt9b6V/H45Um+XlXPSXJea+2aqtonySWttflJ0lr7Q+e5r07y1s66H1fVZlW1Ueex81trD3duvz7JTlX1xDY2qqoNW2uLu7VTAABPl0gEALAKrbVLqmrvJH+d5NSq+qck9z6Dt1oy5PY6SfZqrf2xG2MEAOgG1yQCAFiFqtomyZ2tta8m+VqS3ZNcmmTvqnpJ5zlPnG720yTv7qzbJ8ndrbUHVvC2FyX5H0O20d+j4QMADJsjiQAAVm2fJB+uqkeSLE4ytbX2+6o6LMm/VtU6Se5Ksm+S4zJwatqvkzyU5D0rec+jk5zUed6YJJckObynewEA8BSqtTbaYwAAAABglDndDAAAAACRCAAAAACRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQJL/H+QV1iOQ43ytAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at the importance of each of the features within the model\n",
    "ax = xgb.plot_importance(model, color='red')\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(20, 20)\n",
    "fig.savefig('feature_importance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the trained model\n",
    "preds = model.predict(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export LM.txt ranking\n",
    "\n",
    "unique_qids = val_dataframe['qid'].copy()\n",
    "unique_qids = unique_qids.drop_duplicates()\n",
    "unique_qids = unique_qids.reset_index(drop=True)\n",
    "unique_qids = np.array(unique_qids) # vector of unique qid in the validation set\n",
    "\n",
    "qid_pid_val = val_dataframe[['qid','pid']].copy()\n",
    "qid_pid_val = np.array(qid_pid_val) # (n,2) array, where each row corresponds to the (qid, pid) pair of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_scores = pd.DataFrame(columns=['qid', 'A', 'pid', 'rank', 'score', 'algoname']) # dataframe where we store global results for all queries\n",
    "\n",
    "for qid in unique_qids:\n",
    "    output_info = pd.DataFrame(columns=['qid', 'A', 'pid', 'rank', 'score', 'algoname']) # dataframe where we store \n",
    "                                                                                         # the results for the current query\n",
    "    qid_pairs = qid_pid_val[qid_pid_val[:,0] == qid]\n",
    "    qid_rels = y_pred_val[qid_pid_val[:,0] == qid]\n",
    "    indxs = np.argsort(qid_rels)[::-1]\n",
    "    sorted_qid_pairs = qid_pairs[indxs]\n",
    "    sorted_qid_rels = qid_rels[indxs]\n",
    "    \n",
    "    # Now we just get the top 100 scores (if they are available)\n",
    "    top_sorted_qid_pairs = sorted_qid_pairs[:100,:]\n",
    "    top_sorted_qid_rels = sorted_qid_rels[:100]\n",
    "\n",
    "    # Prepare the array with 'A2'\n",
    "    A2 = np.array(['A2'] * len(top_sorted_qid_rels))\n",
    "\n",
    "    # Prepare the array with the ranks\n",
    "    rank = np.array(range(1,len(top_sorted_qid_rels)+1))\n",
    "\n",
    "    # Prepare the array with the algonamme 'LR'\n",
    "    algoname = np.array(['LM'] * len(top_sorted_qid_rels))\n",
    "\n",
    "    # Put everything together in the output_info dataframe\n",
    "    output_info['qid'] = top_sorted_qid_pairs[:,0]\n",
    "    output_info['A'] = A2\n",
    "    output_info['pid'] = top_sorted_qid_pairs[:,1]\n",
    "    output_info['rank'] = rank\n",
    "    output_info['score'] = top_sorted_qid_rels\n",
    "    output_info['algoname'] = algoname\n",
    "\n",
    "    # Append this query dataframe to the one with global results\n",
    "    LM_scores = LM_scores.append(output_info, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ranking file as LM.txt\n",
    "np.savetxt(r'LM.txt', LM_scores.values, fmt=['%d','%s','%d','%d','%f','%s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess performance of model on validation data\n",
    "For this part we use the mAP and NDCG functions defiend in Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataframes for the functions\n",
    "tq = val_dataframe[['qid', 'queries']].copy()\n",
    "tq = tq.drop_duplicates()\n",
    "tq = tq.reset_index(drop=True)\n",
    "\n",
    "relevancies = val_dataframe[['qid', 'pid', 'relevancy']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ranking data created in previous part\n",
    "LM_ranking = pd.read_csv('LM.txt', delimiter=' ', header=None, names=['qid', 'A', 'pid', 'rank', 'score', 'algoname'])\n",
    "ranking = LM_ranking[['qid', 'pid', 'score']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now copy the AP and NDCG functions from Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mAP function\n",
    "def AP(queries, ranking, relevancies, k):\n",
    "    '''\n",
    "    Function that computes the Average Precision (AP) metric for each query in 'queries', based on a ranking determined by \n",
    "    a retrieval model, where queries are matched with passages from most relevant to least relevant, and based on relevancies \n",
    "    between queries and passages.\n",
    "\n",
    "    Inputs:\n",
    "    queries = data frame of queries for which you want to calculate the AP metric (contains qid and actual query)\n",
    "    ranking = data frame of queries and passages pairs, where higher score pairs are ranked higher (for each query)\n",
    "    relevancies = data frame of relevancies between each possible (qid,pid) pair\n",
    "    k = top k passages you want to take into account when calculating the AP metric\n",
    "\n",
    "    Outputs:\n",
    "    APs = list of AP@k metric for each query, in the same order of appearance as the input list 'queries'\n",
    "    mAP = mean Average Precision of all the queries\n",
    "    '''\n",
    "\n",
    "    APs = []\n",
    "\n",
    "    for q in queries['qid']:\n",
    "        AP_values = []\n",
    "        cum_rel = 0 # cumulative number of relevant passages found in the ranking\n",
    "\n",
    "        max_k = len(ranking[ranking['qid'] == q])\n",
    "        iter = min(k,max_k) # This is because we some queries do not have that many candidate passages\n",
    "\n",
    "        for i in range(1,iter+1):\n",
    "            p = int(ranking[ranking['qid'] == q].reset_index(drop=True).iloc[i-1]['pid'])\n",
    "            relevancy = relevancies[(relevancies['qid'] == q) & (relevancies['pid'] == p)]['relevancy'].values.item()\n",
    "            if relevancy != 0: # we operate when we encounter a relevant passage\n",
    "                cum_rel += relevancy\n",
    "                AP_values.append(cum_rel / i) \n",
    "\n",
    "        if len(AP_values) != 0:    \n",
    "            APs.append(sum(AP_values)/len(AP_values))\n",
    "        else: # we do this to avoid the computing error of dividing 0/0\n",
    "            APs.append(0)\n",
    "\n",
    "    mAP = np.mean(APs)\n",
    "\n",
    "    return APs, mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDCG function\n",
    "def NDCG(queries, ranking, relevancies, k):\n",
    "    '''\n",
    "    Function that computes the Normalized Discounted Cumulative Gain (NDCG) metric for each query in 'queries', \n",
    "    based on a ranking determined by a retrieval model, where queries are matched with passages from most relevant \n",
    "    to least relevant, and based on relevancies between queries and passages.\n",
    "\n",
    "    Inputs:\n",
    "    queries = data frame of queries for which you want to calculate the AP metric (contains qid and actual query)\n",
    "    ranking = data frame of queries and passages pairs, where higher score pairs are ranked higher (for each query)\n",
    "    relevancies = data frame of relevancies between each possible (qid,pid) pair\n",
    "    k = top k passages you want to take into account when calculating the AP metric\n",
    "\n",
    "    Outputs:\n",
    "    NDCGs = list of AP@k metric for each query, in the same order of appearance as the input list 'queries'\n",
    "    mNDCG = mean Average Precision of all the queries\n",
    "    '''\n",
    "\n",
    "    NDCGs = []\n",
    "\n",
    "    for q in queries['qid']:\n",
    "        DCG = 0\n",
    "        IDCG = 0\n",
    "\n",
    "        max_k = len(ranking[ranking['qid'] == q])\n",
    "        iter = min(k,max_k) # This is because we some queries do not have that many candidate passages\n",
    "\n",
    "        # Get the relevancies for the ideal ranking (of the top k candidates??? - doesn't matter for our data tho), in order\n",
    "        sorted_revs = relevancies[relevancies['qid'] == q].sort_values(by=['relevancy'], ascending=False)['relevancy'].values\n",
    "\n",
    "        for i in range(1,iter+1):\n",
    "            IDCG += (2**sorted_revs[i-1] - 1)/np.log2(i+1)\n",
    "\n",
    "            p = int(ranking[ranking['qid'] == q].reset_index(drop=True).iloc[i-1]['pid'])\n",
    "            rel = relevancies[(relevancies['qid'] == q) & (relevancies['pid'] == p)]['relevancy'].values.item()\n",
    "            DCG += (2**rel - 1)/np.log2(i+1)\n",
    "\n",
    "        if IDCG != 0:\n",
    "            NDCGs.append(DCG/IDCG)\n",
    "        else: # we do this to avoid the computing error of dividing 0/0\n",
    "            NDCGs.append(0)\n",
    "\n",
    "    mNDCG = np.mean(NDCGs)\n",
    "\n",
    "    return NDCGs, mNDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP_3, mAP_3 = AP(tq, ranking, relevancies, 3)\n",
    "AP_10, mAP_10 = AP(tq, ranking, relevancies, 10)\n",
    "AP_100, mAP_100 = AP(tq, ranking, relevancies, 100)\n",
    "\n",
    "NDCG_3, mNDCG_3 = NDCG(tq, ranking, relevancies, 3)\n",
    "NDCG_10, mNDCG_10 = NDCG(tq, ranking, relevancies, 10)\n",
    "NDCG_100, mNDCG_100 = NDCG(tq, ranking, relevancies, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1476480836236934 0.17821781151484983 0.19153942472237973\n",
      "0.1623404784203946 0.22750182841012126 0.30431658062579914\n"
     ]
    }
   ],
   "source": [
    "print(mAP_3, mAP_10, mAP_100)\n",
    "\n",
    "print(mNDCG_3, mNDCG_10, mNDCG_100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "989a8ee0261a415be34d4cf0f45e98134ff6fbcaa2e29b3efcaef888d322ba01"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
