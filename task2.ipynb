{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: for the features of the model, instead of using the average embedding vector betqeen query and passage, you could do:\n",
    "1) Cosine similarity between query vector and passage vector\n",
    "2) BM25 score between query and passage\n",
    "3) Length of query\n",
    "4) Length of passage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bcolz-zipline in /Users/joanrossello/opt/anaconda3/lib/python3.8/site-packages (1.2.4)\n",
      "Requirement already satisfied: numpy in /Users/joanrossello/opt/anaconda3/lib/python3.8/site-packages (from bcolz-zipline) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bcolz-zipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text normalisation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(text):\n",
    "    '''\n",
    "    Function that normalises text and returns tokens.\n",
    "    Input: text --> text string we want to tokenise\n",
    "    Output: tokens --> list of tokens taken from the text string\n",
    "    '''\n",
    "\n",
    "    text = text.lower() # convert all to lower case\n",
    "    text = contractions.fix(text) # expand contractions\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))) # remove punctuation\n",
    "    tokens = text.split() # tokenisation\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_words] # remove stop words\n",
    "    # filtered_tokens = list(map(lemmatizer.lemmatize, filtered_tokens)) # lemmatization of nouns\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation\n",
    "- Define a way to transform words into word embeddings --> GloVe\n",
    "- For the data frames of training and validation, replace the text in the actual query and passage cells with word embeddings. For every work in the sentence, we calculate the word embedding with GloVe and then we average the embeddings between all the words in the sentence to get the global sentence embedding. Note that we do not need to worry about padding due to different sentence lengths, because all the word embeddings are vectors of length 50, so the resulting average will also be a vector of length 50, so all the model input data will have the same size.\n",
    "\n",
    "Working with GloVe...\n",
    "- We remove capitalisation and contractions\n",
    "- Should we remove punctuation? It is necessary when the query is actually about the use of some type of punctuation, but this is very unlikely, and it will make it messier in predictions, sow e will remove punctuation\n",
    "- Should we remove top words? Yes, since they do not add meaning of the query to the actual passage, and so for example if a passager has many stop words, and only 2 important words, and then the original query has the 2 important words but no stop words, maybe the model will attribute the passage to a query that also includes many stop words, which would be wrong. Better to eliminate stop words.\n",
    "- GloVe includes all words, so no need to lemmatize? No, no need to lemmatize.\n",
    "- The main problem I see here is with composite words that use punctuation in between. GloVe has them in their vocabulary, but they are hard to tokenise, excluding punctuation but then making exceptions for these kind of words, i.e. 'ar' and 'ar-15'. So for now we will ignore this pitfall, work by removing all punctuation, and see what the performance of the model is like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load training and validation dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = pd.read_csv('train_data.tsv', delimiter='\\t')\n",
    "val_dataframe = pd.read_csv('validation_data.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Set up word embeddings with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in pickled embeddings\n",
    "vectors = bcolz.open('6B.50.dat')[:]\n",
    "words = pickle.load(open('6B.50_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open('6B.50_idx.pkl', 'rb'))\n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Perform normalisation and word embeddings --> prepare input data for logistic regression model\n",
    "- Remember some words in your corpus might not be in GloVe, so you need to replace them by $<unk>$ token.\n",
    "- The query/passage embeddings are calculated as the average of the tokens in the query/passage.\n",
    "- We could 1) concatenate query/passage embeddings, 2) make an average embedding, or 3) compute cosine similarity between centroid of query and passage embeddings.\n",
    "- We tested all 3 options, and we use option 2 since it is the one that yielded the best results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_train = []\n",
    "y_data_train = []\n",
    "\n",
    "def train_data_extraction(row):\n",
    "\n",
    "    q_embed = np.zeros(50) # we chose glove vectors to have length = 50\n",
    "    p_embed = np.zeros(50)\n",
    "    \n",
    "    query = normalise(row['queries'])\n",
    "    for q in query:\n",
    "        try:\n",
    "            q_embed += glove[q]\n",
    "        except:\n",
    "            q_embed += glove['<unk>'] # if the token is not present in GloVe, we assign it as <unk>\n",
    "    q_embed /= len(query)\n",
    "\n",
    "    passage = normalise(row['passage'])\n",
    "    for p in passage:\n",
    "        try:\n",
    "            p_embed += glove[p]\n",
    "        except:\n",
    "            p_embed += glove['<unk>'] # if the token is not present in GloVe, we assign it as <unk>\n",
    "    p_embed /= len(passage)\n",
    "\n",
    "    rel = row['relevancy']\n",
    "    \n",
    "    # x = np.concatenate((q_embed,p_embed)) # concatenate query and passage embedding\n",
    "    x = (q_embed + p_embed) / 2 # average of query and passage embedding\n",
    "    X_data_train.append(x)\n",
    "    y_data_train.append(rel)\n",
    "\n",
    "_ = train_dataframe.apply(lambda row: train_data_extraction(row), axis=1)\n",
    "\n",
    "X_data_train = np.array(X_data_train)\n",
    "y_data_train = np.array(y_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('processed_X_train_data.txt', X_data_train, fmt='%f')\n",
    "# np.savetxt('processed_y_train_data.txt', y_data_train, fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_val = []\n",
    "y_data_val = []\n",
    "\n",
    "def val_data_extraction(row):\n",
    "\n",
    "    q_embed = np.zeros(50) # we chose glove vectors to have length = 50\n",
    "    p_embed = np.zeros(50)\n",
    "    \n",
    "    query = normalise(row['queries'])\n",
    "    for q in query:\n",
    "        try:\n",
    "            q_embed += glove[q]\n",
    "        except:\n",
    "            q_embed += glove['<unk>'] # if the token is not present in GloVe, we assign it as <unk>\n",
    "    q_embed /= len(query)\n",
    "\n",
    "    passage = normalise(row['passage'])\n",
    "    for p in passage:\n",
    "        try:\n",
    "            p_embed += glove[p]\n",
    "        except:\n",
    "            p_embed += glove['<unk>'] # if the token is not present in GloVe, we assign it as <unk>\n",
    "    p_embed /= len(passage)\n",
    "\n",
    "    rel = row['relevancy']\n",
    "    \n",
    "    # x = np.concatenate((q_embed,p_embed)) # concatenate query and passage embedding\n",
    "    x = (q_embed + p_embed) / 2 # average of query and passage embedding\n",
    "    X_data_val.append(x)\n",
    "    y_data_val.append(rel)\n",
    "\n",
    "_ = val_dataframe.apply(lambda row: val_data_extraction(row), axis=1)\n",
    "\n",
    "X_data_val = np.array(X_data_val)\n",
    "y_data_val = np.array(y_data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('processed_X_val_data.txt', X_data_val, fmt='%f')\n",
    "# np.savetxt('processed_y_val_data.txt', y_data_val, fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Prepare input data\n",
    "Input data already prepared in previous section. \n",
    "- We have X data in numpy array of size (n,d) where n = number of (qid,pid) combinations, and d = number of concatednated features = 50 (the input is the average of the query and passage embedding).\n",
    "- The resulting X matrix is a matrix of query and passage embeddings, concatenated.\n",
    "- The resulting y matrix contains the n relevancies of the n (qid,pid) pairs in matrix X. It is a vector of length n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent ( z, loss_func, grad_func, lr=0.01,\n",
    "                       loss_stop=1e-4, z_stop=1e-4, max_iter=100 ):\n",
    "    \"\"\"\n",
    "    Generic batch gradient descent optimisation.\n",
    "    Iteratively updates z by subtracting lr * grad\n",
    "    until one or more stopping criteria are met.\n",
    "    \n",
    "    # Arguments\n",
    "        z: initial value(s) of the optimisation var(s).\n",
    "            can be a scalar if optimising a univariate\n",
    "            function, otherwise a single numpy array\n",
    "        loss_func: function of z that we seek to minimise,\n",
    "            should return a scalar value\n",
    "        grad_func: function calculating the gradient of\n",
    "            loss_func at z. for vector z, this should return\n",
    "            a vector of the same length containing the\n",
    "            partial derivatives\n",
    "        lr: learning rate, ie fraction of the gradient by \n",
    "            which to update z each iteration\n",
    "        loss_stop: stop iterating if the loss changes\n",
    "            by less than this (absolute)\n",
    "        z_stop: stop iterating if z changes by less than\n",
    "            this (L2 norm)\n",
    "        max_iter: stop iterating after iterating this\n",
    "            many times\n",
    "    \n",
    "    # Returns\n",
    "        zs: a list of the z values at each iteration\n",
    "        losses: a list of the losses at each iteration\n",
    "    \"\"\"\n",
    "    losses = [ loss_func(z) ]\n",
    "    zs = [ z ]\n",
    "    \n",
    "    d_loss = np.inf\n",
    "    d_z = np.inf\n",
    "\n",
    "    while (len(losses) <= max_iter) and (d_loss > loss_stop) and (d_z > z_stop):\n",
    "        zs.append(zs[-1] - lr * grad_func(zs[-1]))\n",
    "        losses.append(loss_func(zs[-1]))\n",
    "        \n",
    "        d_loss = np.abs(losses[-2] - losses[-1])\n",
    "        d_z = np.linalg.norm(zs[-2] - zs[-1])\n",
    "    \n",
    "    return zs[1:], losses[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary functions\n",
    "def add_x0(X):\n",
    "    \"\"\"\n",
    "    Prepend a column (or array) of 1s to an array of samples,\n",
    "    as a dummy feature representing bias/offset/intercept.\n",
    "    \n",
    "    # Arguments\n",
    "        X: a table or array of variable values, where the last dimension\n",
    "           indexes the variables\n",
    "    \n",
    "    # Returns:\n",
    "        X: the table or array with all records prefixed with a constant\n",
    "           term x0\n",
    "    \"\"\"\n",
    "    x0 = np.expand_dims(np.ones(X.shape[:-1], X.dtype), axis=-1)\n",
    "    return np.concatenate((x0, X), axis=-1)\n",
    "\n",
    "def reshaped_apply(X, func):\n",
    "    \"\"\"\n",
    "    Apply a function to a data array. \n",
    "\n",
    "    If X has more than 2 dimensions, all but the last are unwound into\n",
    "    matrix rows, and then the results vector y is rewound back into the\n",
    "    original shape of those dimensions. The main use case for this is\n",
    "    to work with grids generated by `make_grid`.    \n",
    "\n",
    "    # Arguments\n",
    "        X: a table or array of variable values, where the last dimension\n",
    "           indexes the values\n",
    "        func: a function taking a single 2d array argument and returning\n",
    "           a vector\n",
    "    \n",
    "    # Returns\n",
    "        y: a vector or array of function outputs for the features in X,\n",
    "           and having a corresponding shape\n",
    "    \"\"\"\n",
    "    rewind = None\n",
    "    if len(X.shape) > 2:\n",
    "        rewind = X.shape[:-1]\n",
    "        X = X.reshape(np.product(rewind), X.shape[-1])\n",
    "    \n",
    "    y = func(X)\n",
    "    \n",
    "    if rewind is not None:\n",
    "        y = y.reshape(rewind)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def affine(X, weights):\n",
    "    \"\"\"\n",
    "    Generic affine function of X computed as X . [weights]^T\n",
    "    \n",
    "    If the weights vector is 1 longer than the number of features in X, we\n",
    "    assume it incudes a bias term in first position, and prepend a\n",
    "    corresponding x0 (=1) to X before multiplying.\n",
    "\n",
    "    If X has more than 2 dimensions, all but the last are unwound into\n",
    "    matrix rows, and then the results vector y is rewound back into the\n",
    "    original shape of those dimensions. The main use case for this is\n",
    "    to work with grids generated by `make_grid`.    \n",
    "    \n",
    "    # Arguments\n",
    "        X: a table or array of variable values, where the last dimension\n",
    "           indexes the values\n",
    "        weights: a vector of coefficients, either the same length as the last\n",
    "           dimension of X, or 1 longer\n",
    "    \n",
    "    # Returns\n",
    "        y: a vector or array of dot products of the input observations\n",
    "           with the weights\n",
    "    \"\"\"\n",
    "    if len(weights) == (X.shape[-1] + 1):\n",
    "        X = add_x0(X)\n",
    "    \n",
    "    return reshaped_apply(X, lambda z: z @ weights)\n",
    "\n",
    "def sigmoid ( z ):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def logistic_forward ( X, w ):\n",
    "    return sigmoid(affine(X, w))\n",
    "\n",
    "def logistic_loss ( X, y, w, eps=1e-10 ):\n",
    "    g = logistic_forward(X, w)\n",
    "    return (np.dot(-y, np.log(g + eps)) - np.dot((1 - y), np.log(1 - g + eps)))/len(y)\n",
    "\n",
    "def logistic_grad ( X, y, w ):\n",
    "    g = logistic_forward(X, w)\n",
    "    return X.T @ (g - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression ( X, y, w0=None, lr=0.05,\n",
    "                          loss_stop=1e-4, weight_stop=1e-4, max_iter=100 ):\n",
    "    \"\"\"\n",
    "    Fit a logistic regression classifier to data.\n",
    "    \n",
    "    # Arguments\n",
    "        X: an array of sample data, where rows are samples\n",
    "           and columns are features. caller is responsible\n",
    "           for prepending x0=1 terms if required.\n",
    "        y: vector of binary class labels for the samples,\n",
    "           must be same length as number of rows in X\n",
    "        w0: starting value of the weights, if omitted\n",
    "           then all zeros are used\n",
    "        lr: learning rate, ie fraction of gradients by\n",
    "           which to update weights at each iteration\n",
    "        loss_stop: stop iterating if the loss changes\n",
    "            by less than this (absolute)\n",
    "        weight_stop: stop iterating if weights change by less\n",
    "            than this (L2 norm)\n",
    "        max_iter: stop iterating after iterating this\n",
    "            many times\n",
    "           \n",
    "    # Returns\n",
    "        ws: a list of fitted weights at each iteration\n",
    "        losses: a list of the loss values at each iteration\n",
    "    \"\"\"\n",
    "    assert(len(X.shape)==2)\n",
    "    assert(X.shape[0]==len(y))\n",
    "    \n",
    "    if w0 is None: w0 = np.zeros(X.shape[-1])\n",
    "    \n",
    "    return gradient_descent ( w0,\n",
    "                              loss_func = lambda z: logistic_loss(X, y, z),\n",
    "                              grad_func = lambda z: logistic_grad(X, y, z),\n",
    "                              lr = lr,\n",
    "                              loss_stop=loss_stop, z_stop=weight_stop, max_iter=max_iter )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Training\n",
    "- Here we make a function for training that also takes the learning rate as a variable, and keeps track of the loss during training. So that later on we can analyse the effect of the learning rate on the model training loss. Note that the training loss will be Binary Cross-Entropy.\n",
    "- Here we obtain a weight matrix w, which we will use in the validation to make predictions, and then compare them to the actual relevancies to analyse the performance of the model.\n",
    "- Note that the logistic regression function returns a list of the fitted weights at each iteration. We are only interested in the weights at the last iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-0ff16e4942a2>:78: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "ws, losses = logistic_regression(X_data_train, y_data_train, lr=0.01)\n",
    "best_w = ws[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Validation\n",
    "Here we rank the validation data (passages for each query) using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-0ff16e4942a2>:78: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "y_pred_val =  logistic_forward(X_data_val, best_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to make a ranking for each query with the results from y_pred_val\n",
    "# Get the (qid,pid) pairs from the validation set, and also the unique qid\n",
    "\n",
    "unique_qids = val_dataframe['qid'].copy()\n",
    "unique_qids = unique_qids.drop_duplicates()\n",
    "unique_qids = unique_qids.reset_index(drop=True)\n",
    "unique_qids = np.array(unique_qids) # vector of unique qid in the validation set\n",
    "\n",
    "qid_pid_val = val_dataframe[['qid','pid']].copy()\n",
    "qid_pid_val = np.array(qid_pid_val) # (n,2) array, where each row corresponds to the (qid, pid) pair of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_scores = pd.DataFrame(columns=['qid', 'A', 'pid', 'rank', 'score', 'algoname']) # dataframe where we store global results for all queries\n",
    "\n",
    "for qid in unique_qids:\n",
    "    output_info = pd.DataFrame(columns=['qid', 'A', 'pid', 'rank', 'score', 'algoname']) # dataframe where we store \n",
    "                                                                                         # the results for the current query\n",
    "    qid_pairs = qid_pid_val[qid_pid_val[:,0] == qid]\n",
    "    qid_rels = y_pred_val[qid_pid_val[:,0] == qid]\n",
    "    indxs = np.argsort(qid_rels)[::-1]\n",
    "    sorted_qid_pairs = qid_pairs[indxs]\n",
    "    sorted_qid_rels = qid_rels[indxs]\n",
    "    \n",
    "    # Now we just get the top 100 scores (if they are available)\n",
    "    top_sorted_qid_pairs = sorted_qid_pairs[:100,:]\n",
    "    top_sorted_qid_rels = sorted_qid_rels[:100]\n",
    "\n",
    "    # Prepare the array with 'A2'\n",
    "    A2 = np.array(['A2'] * len(top_sorted_qid_rels))\n",
    "\n",
    "    # Prepare the array with the ranks\n",
    "    rank = np.array(range(1,len(top_sorted_qid_rels)+1))\n",
    "\n",
    "    # Prepare the array with the algonamme 'LR'\n",
    "    algoname = np.array(['LR'] * len(top_sorted_qid_rels))\n",
    "\n",
    "    # Put everything together in the output_info dataframe\n",
    "    output_info['qid'] = top_sorted_qid_pairs[:,0]\n",
    "    output_info['A'] = A2\n",
    "    output_info['pid'] = top_sorted_qid_pairs[:,1]\n",
    "    output_info['rank'] = rank\n",
    "    output_info['score'] = top_sorted_qid_rels\n",
    "    output_info['algoname'] = algoname\n",
    "\n",
    "    # Append this query dataframe to the one with global results\n",
    "    LR_scores = LR_scores.append(output_info, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to check results\n",
    "# LR_scores[LR_scores['qid'] == unique_qids[990]]\n",
    "# LR_scores[LR_scores['score'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ranking file as LR.txt\n",
    "np.savetxt(r'LR.txt', LR_scores.values, fmt=['%d','%s','%d','%d','%f','%s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Assess performance of model on validation data\n",
    "For this part we use the mAP and NDCG functions defiend in Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataframes for the functions\n",
    "tq = val_dataframe[['qid', 'queries']].copy()\n",
    "tq = tq.drop_duplicates()\n",
    "tq = tq.reset_index(drop=True)\n",
    "\n",
    "relevancies = val_dataframe[['qid', 'pid', 'relevancy']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ranking data created in previous part\n",
    "LR_ranking = pd.read_csv('LR.txt', delimiter=' ', header=None, names=['qid', 'A', 'pid', 'rank', 'score', 'algoname'])\n",
    "ranking = LR_ranking[['qid', 'pid', 'score']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now copy the AP and NDCG functions from Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mAP function\n",
    "def AP(queries, ranking, relevancies, k):\n",
    "    '''\n",
    "    Function that computes the Average Precision (AP) metric for each query in 'queries', based on a ranking determined by \n",
    "    a retrieval model, where queries are matched with passages from most relevant to least relevant, and based on relevancies \n",
    "    between queries and passages.\n",
    "\n",
    "    Inputs:\n",
    "    queries = data frame of queries for which you want to calculate the AP metric (contains qid and actual query)\n",
    "    ranking = data frame of queries and passages pairs, where higher score pairs are ranked higher (for each query)\n",
    "    relevancies = data frame of relevancies between each possible (qid,pid) pair\n",
    "    k = top k passages you want to take into account when calculating the AP metric\n",
    "\n",
    "    Outputs:\n",
    "    APs = list of AP@k metric for each query, in the same order of appearance as the input list 'queries'\n",
    "    mAP = mean Average Precision of all the queries\n",
    "    '''\n",
    "\n",
    "    APs = []\n",
    "\n",
    "    for q in queries['qid']:\n",
    "        AP_values = []\n",
    "        cum_rel = 0 # cumulative number of relevant passages found in the ranking\n",
    "\n",
    "        max_k = len(ranking[ranking['qid'] == q])\n",
    "        iter = min(k,max_k) # This is because we some queries do not have that many candidate passages\n",
    "\n",
    "        for i in range(1,iter+1):\n",
    "            p = int(ranking[ranking['qid'] == q].reset_index(drop=True).iloc[i-1]['pid'])\n",
    "            relevancy = relevancies[(relevancies['qid'] == q) & (relevancies['pid'] == p)]['relevancy'].values.item()\n",
    "            if relevancy != 0: # we operate when we encounter a relevant passage\n",
    "                cum_rel += relevancy\n",
    "                AP_values.append(cum_rel / i) \n",
    "\n",
    "        if len(AP_values) != 0:    \n",
    "            APs.append(sum(AP_values)/len(AP_values))\n",
    "        else: # we do this to avoid the computing error of dividing 0/0\n",
    "            APs.append(0)\n",
    "\n",
    "    mAP = np.mean(APs)\n",
    "\n",
    "    return APs, mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDCG function\n",
    "def NDCG(queries, ranking, relevancies, k):\n",
    "    '''\n",
    "    Function that computes the Normalized Discounted Cumulative Gain (NDCG) metric for each query in 'queries', \n",
    "    based on a ranking determined by a retrieval model, where queries are matched with passages from most relevant \n",
    "    to least relevant, and based on relevancies between queries and passages.\n",
    "\n",
    "    Inputs:\n",
    "    queries = data frame of queries for which you want to calculate the AP metric (contains qid and actual query)\n",
    "    ranking = data frame of queries and passages pairs, where higher score pairs are ranked higher (for each query)\n",
    "    relevancies = data frame of relevancies between each possible (qid,pid) pair\n",
    "    k = top k passages you want to take into account when calculating the AP metric\n",
    "\n",
    "    Outputs:\n",
    "    NDCGs = list of AP@k metric for each query, in the same order of appearance as the input list 'queries'\n",
    "    mNDCG = mean Average Precision of all the queries\n",
    "    '''\n",
    "\n",
    "    NDCGs = []\n",
    "\n",
    "    for q in queries['qid']:\n",
    "        DCG = 0\n",
    "        IDCG = 0\n",
    "\n",
    "        max_k = len(ranking[ranking['qid'] == q])\n",
    "        iter = min(k,max_k) # This is because we some queries do not have that many candidate passages\n",
    "\n",
    "        # Get the relevancies for the ideal ranking (of the top k candidates??? - doesn't matter for our data tho), in order\n",
    "        sorted_revs = relevancies[relevancies['qid'] == q].sort_values(by=['relevancy'], ascending=False)['relevancy'].values\n",
    "\n",
    "        for i in range(1,iter+1):\n",
    "            IDCG += (2**sorted_revs[i-1] - 1)/np.log2(i+1)\n",
    "\n",
    "            p = int(ranking[ranking['qid'] == q].reset_index(drop=True).iloc[i-1]['pid'])\n",
    "            rel = relevancies[(relevancies['qid'] == q) & (relevancies['pid'] == p)]['relevancy'].values.item()\n",
    "            DCG += (2**rel - 1)/np.log2(i+1)\n",
    "\n",
    "        if IDCG != 0:\n",
    "            NDCGs.append(DCG/IDCG)\n",
    "        else: # we do this to avoid the computing error of dividing 0/0\n",
    "            NDCGs.append(0)\n",
    "\n",
    "    mNDCG = np.mean(NDCGs)\n",
    "\n",
    "    return NDCGs, mNDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the preformance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP_3, mAP_3 = AP(tq, ranking, relevancies, 3)\n",
    "AP_10, mAP_10 = AP(tq, ranking, relevancies, 10)\n",
    "AP_100, mAP_100 = AP(tq, ranking, relevancies, 100)\n",
    "\n",
    "NDCG_3, mNDCG_3 = NDCG(tq, ranking, relevancies, 3)\n",
    "NDCG_10, mNDCG_10 = NDCG(tq, ranking, relevancies, 10)\n",
    "NDCG_100, mNDCG_100 = NDCG(tq, ranking, relevancies, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0030487804878048786 0.005420399867263979 0.008302550194078372\n",
      "0.0036579815828371963 0.008514783474616615 0.024729627517578595\n"
     ]
    }
   ],
   "source": [
    "print(mAP_3, mAP_10, mAP_100)\n",
    "\n",
    "print(mNDCG_3, mNDCG_10, mNDCG_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Analyse the effect of the learning rate on the model training loss\n",
    "For this we use the 'train' function defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-0ff16e4942a2>:78: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.5,0.1,0.05,0.01,0.001]\n",
    "loss = []\n",
    "its = []\n",
    "\n",
    "for l_r in lrs:\n",
    "    _, losses = logistic_regression(X_data_train, y_data_train, lr=l_r, loss_stop=1e-5, weight_stop=1e-5)\n",
    "    loss.append(losses)\n",
    "    its.append(len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABVcElEQVR4nO3dd3gU5fbA8e/JptJDCC0BAoTeAoSmgiiggEqxUSxYsV/7T1RUxO61XPtVVECkgyBIFSxYaAFCl95776Se3x8zeGPYQCDZTQjn8zz7sDvzzrtndsiefaecEVXFGGOMyamAvA7AGGNMwWAJxRhjTK6whGKMMSZXWEIxxhiTKyyhGGOMyRWWUIwxxuQKSygXIRF5VUT2ishO93VXEdkiIkdFpGEexnXGOERERSQ2D+K6RUSm+/t9Lwbn8tn6cjuIyEYRaeuLvi8mYtehFDwishEoA6RlmDxIVR8WkYrAKqCSqu52268DnlDV73P4vgpUU9W157n8GePIaf8FgYjcAdyjqpflg1gGAVtVtW9ex5JT7t/MPao6I69juZAF5nUAxmeuy+KPoyKw71QycVUClvsnrDPyexwiIjg/rNL9+b5ZxBKoqql5HUduKWjrY7JBVe1RwB7ARqCtl+ltgRNAOnAUGO7+q8AxYJ3brjwwFtgDbAD+laEPD/AcsA44AiwAKgCzMvRzFOjm5f0DgL7AJmA38A1QHAjxFoeX5RWIdZ+HAO8Am4FdwH+BMHdeOPCDG/8B93l0hn5+AV4D/nA/j1i37/uBNcBB4BP+N4K/A/g9UxxZtfUA7wJ73c/uYbd94Bm21TPAEiAJ50denwyf7wqgq9u2FnASZ+R5FDh4ts8iu9vAnRfjxtrL7Wsv8HwW/fQGUoBkN5aJ57o+5/HZ+no7tM3wef4H2O4+/gOEuPNK4fx/OgjsB34DAtx5zwDb3PVcBbTJ6+8Cv3/35HUA9vDBRs0iobjzWuPspsg4LeMXdQBOkngRCAaqAOuBq935TwNLgRqAAA2AiMz9ZPHedwFr3T6LAN8BQ7zFkcXyGeN8H5gAlASKAhOBN9x5EcANQCF33mhgfIZ+fsH5wqzjfuEFuX3/AJTAGcXtAdq77b19kWXV9n6cL81onMQ2IxtfZIk4SflUQrwJJ6kHAN1wkmw5b7Gc7bM4l23A/xLKACDM3bZJQK0s+hoEvJqb65PH2+FUQukPzAFKA5HAn8Ar7rw3cBJ2kPtoifN3UAPYApTP8FlWzevvAn8/8jwAe/hgozp/HEdxfkWdetzrzmvNmRNKM2BzpvnPAgPd56uAzlm879kSwkzgwQyva+D8yg3M5vKKM5oQ90upaoZ5LYANWSwXBxzI8PoXoL+Xvi/L8HoU0Md97u2LLKu2PwH3ZZjXNhtfZHedZXsmnvrMvcRyrp9FltuA/yWUjKO5eUD3LPoahPeEkpP1ycvtcCqhrAM6Zph3NbDRfd4f+D7z/1P3/+Vu932CzrT+Bflhx1AKri56fgcYKwHlReRghmkenKE9OL88151nTOVxdrWcsgnni6wMzq6C7IrEGX0scA6BAM4XqwdARArh/Gpvj/PrFKCoiHhU9dSJClu89Lszw/PjOL/gs5JV2/KZ+vb2Ppn9o42I3A48gfMFj9t3qSyWPeNn4cWZtsEp5/I5eJOT9TnX98/N7XCKt8+ovPv830A/YLr7eX+hqm+q6loRecydV0dEpuGcYLL9HN73gmenDZvMtuD8ui2R4VFUVTtmmF/1PPvejpOwTqkIpOLs9z8Xe3GOfdTJEGNxVT31ZfIkzi/vZqpaDGjlTpcMfeg5R589O3B2s5xSIRvL/B2LiFTC2eX0MM6uxBLAMv4Xe+a4z/ZZZJZb28BbLKdNz8b6+Mr5bIdTvH1G2wFU9YiqPqmqVYBOwBMi0sadN0yds+8q4XwGb+Ug/guSJRST2TzgiIg8IyJhIuIRkboi0sSd/yXwiohUE0d9EYlw5+3C2TefleHA4yJSWUSKAK8DI/UczwRS54ysAcD7IlIaQESiRORqt0lRnC/ZgyJSEnjpXPrPoVHAo248JXAO1J6LwjhfRnsAROROoG6G+buAaBEJhmx9FpnlyjbIEMuZtnd21sdXcrIdhgN9RSRSRErhHE/8FkBErhWRWPfswEM4J0iki0gNEblSREJwTpw4dfLLRcUSSsE10b1A8NRjXHYWcncJXYtz3GEDzi/gL3HOxgJ4D+ePdTpwGPgK5wAuOMP9wSJyUERu9tL918AQnDPCNuD84T1y7qsGOF8Qa4E5InIY56BrDXfef9yY9uIcXJ16nu9xPgbgfDZLgEXAZJwRQNqZFjpFVVfgnJ00G+cLux7O2Win/IRzavVOEdnrTjvTZ5FZbm6Dr4Da7vYef57r4ys52Q6vAgnuskuBhe40gGo4n+9RnHX6VFV/xjkz7E2c/3M7cQ7oP5tL63LBsAsbjfEhEekA/FdVK521sfEZ2w7+YSMUY3KRu5uwo4gEikgUzu62bI0OTe6x7ZA3bIRiTC5yzzD7FaiJsx99EvCoqh7O08AuMrYd8oZPRygi0l5EVonIWhHp42V+iIiMdOfPFZGYTPMruvv/n8ow7WsR2S0iyzK1LSkiP4rIGvffcIzxM1U9rqpN3DPjSqvqnfYl5n+2HfKGzxKKiHhwSiF0AGoDPUSkdqZmd+NccBaLc91A5tPs3gOmZJo2COf6gsz6ADNVtRrOxVunJTBjjDG+48sLG5sCa1V1PYCIjAA645RDOKUzzplBAGOAj0VEVFVFpAvOWSjHMnaqqrMyj2Qy9NXafT4Y52roM54qWKpUKY2J8daVMcaYrCxYsGCvqkZmnu7LhBLFP69O3YpT1sNrG1VNFZFDQISInMRJBu2Ap8ieMqq6w32+k39e+fs3EemNU9iOihUrkpCQkM3ujTHGAIjIJm/T8+tZXv2A91X16PksrM6ZBl7PNlDVL1Q1XlXjIyNPS7DGGGPOky9HKNv4Z7mDaE6v13SqzVYRCcS5eG4fzkjmRhF5G6eSaLqInFTVj8/wfrtEpJyq7hCRcjiF2owxxviJL0co84FqbomHYKA7TontjCbg3HsB4EbgJ3W0VNUYVY3Buer59bMkk8x99cKpCGqMMcZPfDZCcY+JPAxMw6l8+rWqLheR/kCCqk7AKd0wRETW4tyspvvZ+hWR4TgH30uJyFbgJVX9CqfswSgRuRunOqi30h/GmAIqJSWFrVu3cvLkybwOpcAIDQ0lOjqaoKCgbLW/qC9sjI+PVzsob0zBsGHDBooWLUpERAQZSvmb86Sq7Nu3jyNHjlC5cuV/zBORBaoan3mZ/HpQ3hhjzsnJkyctmeQiESEiIuKcRnyWUIwxBYYlk9x1rp+nJZTzMHr6h7w2sCdJyUl5HYoxxuQbllDOw/ERQ6g7ZBEPfhzP9N/H53U4xph8okiRc71b8tmpKv/617+IjY2lfv36LFy40Gu71q1bU6NGDeLi4oiLi2P3bv9fOWEJ5Tx06fYqVfcEcPvIVD6b/RxvfHojJ5JS8josY0w+lJp6PjfD/J8pU6awZs0a1qxZwxdffMEDDzyQZduhQ4eSmJhIYmIipUuXztH7ng9LKOeh+NVXU3XocEoHFOeFb5XEvSt5bUAHjicl53Voxph84JdffqFly5Z06tSJ2rUz18Q9N99//z233347IkLz5s05ePAgO3bsOPuCecCXV8oXaGH161N19Fg29+7Ni8PXM7LlDl76oj0v3TOFImEheR2eMRe1lycuZ8X23K1WX7t8MV66rk622y9cuJBly5addsotQLdu3Vi1atVp05944gluv/32f0zbtm0bFSr8r+hIdHQ027Zto1y5cqctf+edd+LxeLjhhhvo27ev309SsISSA8HRUVQeOYIdL71Ej8lTWLFhB/2PXUGrln1p37w9gR4bABpzsWratKnXZAIwcuTIXH+/oUOHEhUVxZEjR7jhhhsYMmTIacnJ1yyh5JCnaFGi3n2Xg61akfzic8R+e4Clvz/F6zFPkVo1mi5Xv0Cj2i3zOkxjLirnMpLwlcKFC2c571xGKFFRUWzZ8r/C7Vu3biUqKuq0ZU9NK1q0KD179mTevHmWUC5EIkJ4ly4Ujo9n3YdvUPO3P2i8Non0mVv4ee59jIgvSuuGj9Hhyu52nrwx5pxGKJ06deLjjz+me/fuzJ07l+LFi5+2uys1NZWDBw9SqlQpUlJS+OGHH2jbtm1uh31WllDOw54tRzi85wRVG/3zLIrg6Ghqvf0Jqkry+vWs/fwDWv/wIynLDzNx1SvMWzaQB24dSZkIuzuxMSZ7OnbsyOTJk4mNjaVQoUIMHDjw73lxcXEkJiaSlJTE1VdfTUpKCmlpabRt25Z7773X77FaLa/zqOU1Y9AKVs3ZSdWGkbTsXp3CxbM+CJ+8cSOb3nyF1F/+ZEmM8OdVAVzb5EPatbwyJ6EbYzJZuXIltWrVyuswChxvn6vV8spFV9xWk+ZdqrBx6T6GvzyXv2bvIKvEHBwTQ7X/fkXZN16j7ha4bmwaw+Y8xPuf3cXeg4f8HLkxxviOJZTz4PEE0Lh9DN36NqFkucLMHLySCR8kcmjP8SyXCe96PTFfD6JcUhgPDIOVG+fyyPAWDBzXD01P92P0xhjjG5ZQciC8bGG6PtmIy3tUZ9fGwwzvP4+F0zaRnuY9QRRu1pTY0WOJqFSDx79Pp8cYZdyqMTw8oBVHjh70b/DGGJPLLKHkkAQIdS+PpudLzalYuySzx61jzFsL2Lv1iNf2IZUrU2XsWMr2f5kax8N5c1AaNX7Zz4Nft2LNpqV+jt4YY3KPJZRcUiQ8hI4P1Ofqe+ty9MBJRr+ewNwJ60lLPX20Ih4P4TffTOz0aUT0up22icpDg1L48sNufDvpNdLT0vJgDYwxJmcsoeSy2Mal6flSc6o1KUPC5I2MeSuBfduOem3rKVqUMs8+S5WxYwktW547JinF//0tLz5bn69H/h/JSXYrU2PMhcOnCUVE2ovIKhFZKyJ9vMwPEZGR7vy5IhKTaX5FETkqIk+drU8RGSQiG0Qk0X3E+XLdziS0SBBt76xNh/vrcexgEqPemM+iHzej6d7PBAutXZsGE6dT8qW+lEsK5ZYJ6ZT/eCKvv9aCffv3+jl6Y8z5ysvy9c8//zwVKlTwSQzZ5bOEIiIe4BOgA1Ab6CEimctu3g0cUNVY4H3grUzz3wOmnEOfT6tqnPtIzM31OR9V4iLp/kIzKtWJ4M+xa/n+P4s4st/7qEM8Hsr0uIXGv82n9OuvEZESTOdxJ/nPu1eyYdsmP0dujMkt/ipff9111zFv3rwcvVdO+XKE0hRYq6rrVTUZGAF0ztSmMzDYfT4GaCNubRIR6QJsAJafY5/5SqFiwXS4vx5X3l6T3ZuOMOKVeayetzPL9hIYSMT119Nw4gxSw4tww/cpfPlJRxatWubHqI0xOZEX5eubN2/utQKxP/my9EoUsCXD661As6zaqGqqiBwCIkTkJPAM0A54ylv7LPp8TUReBGYCfVT1tHv0ikhvoDdAxYoVz2O1zp2IUOuS8pSvVoIZA1fw49cr2LB4L5f3qEFokSCvywRGRtJw3FQW33QNN084xIjUm9l13Ru0b5mv86cx+cOUPrAzl8+aLFsPOryZ7eZ5Ub4+r+XXWl79gPdV9eg5FFN8FtgJBANf4CSk/pkbqeoX7nzi4+P9WnemeGQhuj7ZiIXTNjN/0ga2rznIFbfVJKZeKa/tAyMiaDB2Cst6dOH2Cbv5aWsfvt2+iFu79fNn2MaY8+Dv8vX5gS8TyjagQobX0e40b222ikggUBzYhzPquFFE3gZKAOnuqGVBVn2q6qkxYJKIDOSfI5t8I8ATQHzHGCrVi2DmoBVM+mQJtS4px2U3VSM47PTNERgeTv3vp7Pypae4cvwMNm8ZyScbErjr0dGEhYXlwRoYcwE4h5GEr/i7fH1+4MuEMh+oJiKVcb70uwM9M7WZAPQCZgM3Aj+pUxTr7xuIiEg/4KiqfuwmHa99ikg5Vd3hHoPpAuTrgw6RFYpyU58mzJu0gUXTNrHlr/1ceXstKtQseVrbgJAQ6rz5EdsuH0/E888ROWwdH+9uSstbPqN548vyIHpjTE7kdvn6/MJnB+VVNRV4GJgGrARGqepyEekvIp3cZl/hHDNZCzwBnHZqcXb6dGcPFZGlwFKgFPBqbq9TbvMEBdCiS1Wu/7/GBAZ5mPCfRGYNX0XySe9nhUR16ELdSTM4Uboo105OZe5H9/LJgMc4fNyuVzGmoOrYsSNVqlQhNjaWe++9l08//fTveXFxcX8//7//+z+io6M5fvw40dHR9OvXz++xWvn68yhf7wspyWnMHb+exT9voVhEKG161aZ8tRJe26YnJbH4iXsInZnA0krCwssCaNb8Mbq2u8e/QRuTj1j5et+w8vUXoKBgD5fdXI2uTzQEYNx7C/lt5Gqvo5WAkBDiPv6G4n37UGOXh1uHpbFp4Hs8+J94xvw4gOQUK91ijPE/G6HkkxFKRsknU5kzfj1Lf9lK0ZKhtL61BhVrR3htm3rgAFvefYvjY78nxQN/1BY21w6gYtWu3HHTixQO9X5asjEFjY1QfMNGKBe44NBAWnWvTtenGuEJCmDih4uZMXAFxw8nn9Y2MDycyq++SewPP1Di2mtotVK4Y0Qa5QaP4d03mzFrQd5eOWuMuXhYQsnHyseWoFvfJjTuUIk1CbsY+tIclv6ylXQvNcFCqlYl5s13qP3nHEo8/TiV93voOuoESz7oxX8+eYCjJ09PRsYYk5ssoeRzgUEemneuSvcXmhJZsSizRqxmzJsJ7Fzv/fbBnqJFKXd3b+rN/I20K+JpMw/ihvzCBy83Zf6yP/0bvDHmomIJ5QIRXrYwnR+L46q763D8UBJj317AzG9Wet0NBs6usLhPhlDmq/9SKCCE68clMff1u3ln4F0kp+SsWJ0xxnhjCeUCIiJUa1KGni83p2G7iqyes5NvX5zNwmmbSM3izK6Sl15O/Iw/Sb22NW0WQuPPZ9P3tcYMnzGdpFQ7G8yY3JSX5esXLFhAvXr1iI2N5V//+henTrjq168fUVFRxMXFERcXx+TJk3M9xlMsoVyAgkMDueSGWLq/2JSoaiWYPW4dw/rNZc38XV7vuRJQqBD13vmM6MEDKZ4ezK2jk1k17lFeeO9u/liddeVjY0zO+at8/QMPPMCAAQP+bjt16tS/5z3++OMkJiaSmJhIx44dcxTPmVhCuYCFly3MNQ81oNOjcQSHBjL9q+WMemM+G5fuxdvp4EWbNaf+tF8IbFSbbjOh1h/zGD+iDe9/28+uXTEmF/m7fP2OHTs4fPgwzZs3R0S4/fbbGT9+fI7e93zk12rD5hxUqFWSm59vwpr5u5g3cT2TPllC2SrFiL+mMhVrlyRjxebA8HBqDR7Nzs8/o8knn9J8VTqrokby73lj8NSrx2VNbuOSelcT4PHk4RoZkzNvzXuLv/b/lat91ixZk2eaPpPt9v4sX79t2zaio6NPa3PKxx9/zDfffEN8fDzvvvsu4eHh2V6Pc2EJpYAICBBqNCtLbHxpVv6xgwVTNvLDR4spXako8R1jiKlXCglwEosEBFDugYeI7N6TvWNGEjXoC2pMP0HqjESWxixmetWnOFk6jOByFahSphE9r3qK0JBCebyGxlxY8kv5+gceeIAXXngBEeGFF17gySef5Ouvv/bJe1lCKWA8ngDqtoqi1iXlWDVnJwumbmTyZ0spWb4wja6qSGyTMng8zp7OwPBwyt57P2XuuY8TixJZO2oQ1X+dRcMfTwLHSQ1YxZbIVbzyx2h63P0ldatlvj+aMfnTuYwkfMWf5eujoqLYunWr1zZlypT5e/q9997Ltddee24rcg4soRRQnsAAal9WnpotyrImYTcLp21ixqCVzJ2wgYZXVaTWJeUIDHZ2a4kIhRo1pH6jhqgqyRs3krRyJQcWL6DU5O+5dfwxpuy8g8VdenJLlxfyeM2MufDldvn6cuXKUaxYMebMmUOzZs345ptveOSRRwDn+Mqp9uPGjaNu3bq5tyKZWEIp4AI8AdRoVpbqTcuwaek+FkzdyKwRq5k/eSNxbSpQp1UUIRlu7CUihFSuTEjlyhTr2JEKjz/N4icfoMPMOazYNox+i8bT5IoHuKa1VTY2xh86duzI5MmTiY2NpVChQgwcOPDveXFxcSQmJgLw6aefcscdd3DixAk6dOhAhw4dAKesfWJiIiJCTEwMn3/+uc9iteKQ+bA4pC+pKtvXHGTB1E1sWbGfoFAPdS4rT4M2FSgSHprlcttHfsveV18nKEXZXRzWxAZA61bc0O0Vwot5v4WxMf5kxSF941yKQ9oI5SIjIkRVDyeqejh7Nh9h0Y+bWfzTVpb8tJVqTcvQsF1FIqJOvzirfLdbKdOhE9snfseOEf+l2aJDpC75hY8SWrGvQSl6XtqXZg2uyoM1MsbkFzZCuchGKN4c3nuCxTO3sOKP7aQmp1OpbgRNrq1MmZhiWS5zYssWFj/Zm+JLNrI5Er65Wris2lXcf9N7SIBd3mT8z0YovmHl6805KVYqjJbdqtPr9Utp1qkyuzYcZsybCUz9fCkHdh7zukxYhQo0HzWF6E8+poKWpO+3Ssr46fT5sCX79tvV98ZcjHyaUESkvYisEpG1InLa/eJFJERERrrz54pITKb5FUXkqIg8dbY+RaSy28dat89gX65bQRRaJIj4jpW57dUWNLm2MptX7Gf4y3P5ddgqThz1XoSyaJs21Jg6nWK33kKbRKXLkP38p/8VvPVVD3bt2e7nNTDG5CWfJRQR8QCfAB2A2kAPEclcg+Bu4ICqxgLvA29lmv8eMCWbfb4FvO/2dcDt25yH4LBAml7rJJa6l0ez/PftDH1xDkt+3kJ6Wvpp7T1FChPVty9VxowhOLIMPadC3KBEXn+vDW8N6Mn+g4fzYC2MMf7myxFKU2Ctqq5X1WRgBNA5U5vOwGD3+Rigjbh1QkSkC7ABWH62Pt1lrnT7wO2zS66v0UUmrGgwrbpXp9vzTYisWJTfRq5h1Ovz2b72oPf2derQaPJPlH/3XcpICe4fB+UmJPLsoBYMHT+Qk1YvzJgCzZcJJQrYkuH1Vnea1zaqmgocAiJEpAjwDPByNvuMAA66fWT1XgCISG8RSRCRhD179pzzSl2MIqKK0OnRONrfV5ekE6mMe2chMwat4MSR03eDSUAAxa/pSIOZsyj19FPEr1U6jU9n6Oa3efejTuw+YKMVU3Dlx/L1o0ePpk6dOgQEBODrk5Dy60H5fji7r47mdseq+oWqxqtqfGRkZG53X2CJCFUblqbnS81p1L4Sa+bvYvgr89i8fJ/39kFBRN59NxU++4wqB0PoOzSA33QTrw1tzbpN6/wcvTF5J6/L19etW5fvvvuOVq1a5SiO7PBlQtkGVMjwOtqd5rWNiAQCxYF9QDPgbRHZCDwGPCciD5+hz31ACbePrN7L5IKgEA8tulTlpmebEFo4iIkfLeb3UWtISzn92ApA0datiRnyLaUCw3l7sBKwNomnpl7H7wsm+TlyY/wnP5Wvr1WrFjVq1MhRDNnlywsb5wPVRKQyzpd7d6BnpjYTgF7AbOBG4Cd1xmktTzUQkX7AUVX92E0Yp/WpqioiP7t9jHD7/N6H63bRKxVdhJufjefPsWtZ/NMWtq05wNX31KVEmdOrEofVq0vlsWPY8dxz9J46myWr4c2kp3khMMguhjQ+sfP110lambvl60Nq1aTsc89lu31+Kl/vLz5LKKqa6o4qpgEe4GtVXS4i/YEEVZ0AfAUMEZG1wH6cBHHOfbqznwFGiMirwCK3b+NDgcEeWvWoQYU6EcwcvIKRr8+ndc8a1GhW9rS2QWXLUuHLLzkwdBj1/v02z32TwkdJjxFRfCSxMfXyIHpjfCu/lK/3J5+WXlHVycDkTNNezPD8JHDTWfrod7Y+3enrcc4CM35WuX4puvdtyvSvljNj4Aq2rNhPy+7V/1F0EpwD9iVvu5VCTZuw9pYe9B59grfpwWt3/UhkRLksejfm3J3LSMJX8kv5en+yWl4mVxQJD6XL4w1JmLyRhCmb2L7mIG3vrE35aiVOaxtaowZVBw9Bb+lBt+9S6C/t6dXuA+IbtPZ73MbkBX+Wr/en/HqWl7kABXgCaHpdFa5/qhHiEca9t5A/v1vr9YB9WJ06VB04mNLHPNw0KpnvvnyQ/h91ZMvOrV56Nubi1bFjR6pUqUJsbCz33nsvn3766d/z4uLi/n7+6aefcs899xAbG0vVqlX/Ll8/btw4oqOjmT17Ntdccw1XX321z2K14pBWHNInkk+m8seYtaz4fTsRUYVpe2dtSkUXPa3d8YWL2NDveQJWb+BoKMyuD1vqF6d8mUu4osm9xNW0Yn8me6w4pG9YcUiT54JDA7ni1ppc81B9jh9JYfQbCSRM3khaptIthRo1pPb3k6g0bBhatxpt50GPbw5x5NepPPHzDbw75BEu5h89xlxILKEYn4qpV4oeLzalcoNI5k5Yz5g3E9iz+cg/2py6BXHTbydQ9YeJlLq8DTf9rrz9hbJ9/k889t8rOHz0UB6tgTEmu86aUETkUREpJo6vRGShiNjFAybbwooE0753XdrfV5djh5IZ/WYCs8evIzX59NpeIbGxVPzoY2JGjyaibmPumZ5Ox2G76P/Gpbw39D7+Wpvo/xUwxmRLdkYod6nqYeAqIBy4DXjTp1GZAskp3dKMGs3KsHDqJoa/Mo8tK/Z7bRtWry4x3wwh6sMPKJ1aiLvHphH38SzGvNGTx1+vx3dT/+vn6I0xZ5OdhCLuvx2BIe6FhHKG9sZkKbRwEG161abz4w0RgQkfJvLj18s5fthLoUkRil11FQ1++ZOyr75CePkqXP+Hcs83qawY/SF9Pm3Pjr1W4NOY/CI7CWWBiEzHSSjTRKQo4L1wkzHZFF0jnO4vNCX+mhjWLtzNsH5zWPHHdq8H4ANCQgi/8UYajp1EtV9/IbRDW274Q6k7aTNPDmvNlD8n5sEaGGMyy05CuRvoAzRR1eNAEHCnT6MyF4XAIA/NrqtC975NiYgqws9D/uL79xdxZP/JLJcJKlOGKu99SNmXXqThRqH3sHQGz3qGoVM+8mPkxniXH8vX79+/n3bt2lGtWjXatWvHgQMHAPjrr79o0aIFISEhvPPOO7kSa3YSSgtglaoeFJFbgb449y0xJleEly1Ml8cbcsVtNdm9+QgjX53H2gW7s2wvIoT36EHlb7+ldEBxnv1WmTvzMz4a9YQfozYme/K6fP2bb75JmzZtWLNmDW3atOHNN51D4CVLluTDDz/kqaee8trf+chOQvkMOC4iDYAngXXAN7kWgTGABAi1Ly1Pt+ebUqJMIaYNWMZP36z0eibYKYUaNqT69xMJq1OHB35QUr6fymtf3kJ6ul23YvJWfipf//3339OrVy8AevXq9ff00qVL06RJE4KCgnIUX0bZqeWV6paH7wx8rKpfiYjdr934RPHIMLo+1Yj5P2xgwZRN7N16lI4P1KNIeKjX9oGRkVT7djhb33ydDkNH8HPKIvonX88zd48mLMRK1V2sfhu1mr1bcvf+fKUqFKHlzdWz3T6/lK/ftWvX323Lli3Lrl27sr0O5yo7f3FHRORZnNOFW4pIAM5xFGN8wuMJoHnnqpSJKcaPA1cw6o0EOvSuS7nYEl7bS1AQFV54iR1FinLF5wMYWnIV//5vZ+6/YzSli59+fxZj/CE/lq8XEUR8d5JudhJKN5wbY92lqjtFpCLwb59FZIyrcoNIbvy/eCZ/toTx7y/iyttreb3XyillH3uclE2buGXqdN4N38jAIb155uFv/RixyS/OZSThK/mlfH2ZMmXYsWMH5cqVY8eOHZQuXfq81ic7znoMRVV3AkOB4iJyLXBSVe0YivGLkuULc2OfeMrFFmfGwBXMn7Qhy9peIkL0m28RXL8ej0xMZ9nhBcz8c7qfIzbm7EaOHEliYuJpj8zJBJzy9d988w2qypw5c85avl5V+eabb+jcufPfyw8ePBiAwYMH/z3dF7JTeuVmYB7OjbBuBuaKyI0+i8iYTEILB3HdI3HUaF6WeRM38NPglaSler8UKiA0lEqffkpQeEnuHQ8//Pk0J5NT/BuwMbkop+Xr+/Tpw48//ki1atWYMWMGffr0AWDnzp1ER0fz3nvv8eqrrxIdHc3hw4dzFOtZy9eLyGKgnarudl9HAjNUtUGO3jkfsPL1FxZVJWHyRuZN3EB0zXA63FeP4DDve21PLF3Kuu7dWFoR9tzcin/daaVaCjorX+8buV2+PuBUMnHty+ZyiEh7EVklImtFpI+X+SEiMtKdP1dEYtzpTUUk0X0sFpGuGZZ5VESWichyEXksw/R+IrItw3IdsxOjuXCICE2uqcyVt9di++qDfPfuQo4dTPLaNqxePcr27UvcBiVl1q+sWLXAz9Eac/HJTmKYKiLTROQOEbkDmISXe7pnJiIe4BOgA1Ab6CEimU/Ivhs4oKqxwPvAW+70ZUC8qsYB7YHPRSRQROoC9+LcO74BcK2IxGbo731VjXMfZ43RXJhqXVKOax6qz6E9JxjzdgL7tns/PTSiew+SrmxKx9kw+tNbGfb9v+3eKsb4UHYOyj8NfAHUdx9fqOoz2ei7KbBWVderajIwAsh8NKgzMNh9PgZoIyKiqsdV9dTlpaHAqW+BWsDcDPN/Ba7PRiymgKlYJ4Lrn2xEeqoy9u0FbFq277Q2IkL99z7neI1obp4GJwYN5Ln3W7N47WpLLAWUbdfcda6fZ7Z2XanqWFV9wn2My2bfUcCWDK+3utO8tnETxCEgAkBEmonIcmApcL87fxnOtTARIlIIp2BlhQz9PSwiS0TkaxEJ9xaUiPQWkQQRSdizxyrVXsgiKxblxj7xFI8MY9Ini1k8c8tpfwABoaE0GjuFIg/eS7NVyrXDdvPdO13o1yeOtz7oweTfv+fYiaxrh5kLR2hoKPv27bOkkktUlX379hEa6v2iYm+yPCgvIkf438jgH7Oc99JiZ+zYOROsvare476+DWimqg9naLPMbbPVfb3ObbM3Q5taOKOYVqp60r1K/0HgGLAcSFLVx0SkDLDXjfkVoJyq3nWmGO2gfMGQkpTGjIErWJ+4h5rNy9KqZw2Cgj2ntTuxfDlrnniIoE3/u1J4bnXhiy5CTEoQ9QrV54mbPyckJMyf4ZtckpKSwtatWzl50n4g5JbQ0FCio6NPK8+S1UH5LC9sVNWiOYxlG/8cPUS707y12SoigUBxnIP+GeNYKSJHgbpAgqp+BXwFICKv44x8UNW/vyVEZADwQw7jNxeIoBAP7XvXZf6kDcyfvJE9W47S/r66lCj9z6vkw+rUof60X0g9cICkNWvZ8McEwo6sprHuZUPAHoalL2L+4GY81KAvbZrdnEdrY85XUFBQllemG/8462nD592xkyBWA21wEsd8oKd7g65TbR4C6qnq/SLSHbheVW8WkcrAFlVNFZFKwGygvqruFZHSqrrbvWJ/OtDcrYRcTlV3uP0+jjPS6X6mGG2EUvBsWr6PH79ejqYprW+tSbX4MtlaTlX5dHwfRhz4gaMBQiepw8u98qY8hjH5XU5OGz4v7jGPh4FpwEpglKouF5H+ItLJbfYVECEia4EncO67AnAZsFhEEoFxwIMZdoONFZEVwETgIVU96E5/W0SWisgS4ArgcV+tm8m/KtWJ4ObnmlCibGGmf7mcGYNWkHzi7OXDRYSHur7FsA7jaZhcmO9YwYDv+/k+YGMKEJ+NUC4ENkIpuNLS0kmYtJEFUzZSNCKUNr1qUb6a1/M0TnP02CF6DmvJfk8aHzQfQOPal/g4WmMuLOc9QhGRR7I6Y8qY/MrjCaBZpyp0faoxAOPeXcTPQ1Zy8tjZy7AUKVycly59l2SBt397gMPHjvk6XGMKhOzs8ioDzBeRUe6V776rfWxMLitXtTjdX2hGw3YVWTl7J8NensuahF1nPbW0ce123FWyPStC03lxSBd27d/vp4iNuXBla5eXm0SuwrmXfDwwCvhKVdf5Njzfsl1eF5c9m4/w87d/sWfzEWLql+LyHtWzvHEXOAfqHxl0Jb8G7KVsSjqtg5vyUNd3KVG0pB+jNib/ydFBeXWyzk73kQqEA2NE5O1cjdIYH4qsWJQbn2nMJTfEsnXlfoa9PJdls7adsRz+h71m8HKlXhTVQEZoAjeNbMnP88b6OXJjLgzZqTb8KHA7zkWDXwLjVTXFvXPjGlWt6vswfcNGKBevQ3tO8MvQv9j61wEq1i7JFbfVokh4SJbtNT2dETPe479bBpIs8HDkLdxy3XN+jNiY/COrEUp2EsrLwNequsnLvFqqujL3wvQvSygXN1Vl+axt/DF2LZ7AAC7vUYNqTc583cqydfN4+ud72BWYzq0axwPdBxAWZlfWm4vLeScUd+FGONeGKPCHqi7M/RD9zxKKATi46zgzBq1g14bD1GxelpbdqxMcmvXdsXcf3M6DYzqzKugk9U+k06pYF7p3eZHihbIe4RhTkOTktOEXcGppRQClgIEi0jf3QzQmb5QoU4jrn2pEk2tiWDV3JyNfm8+uDVnfua50ifIM6/U7d5Zsz+bgAD5OmcBjg+JJWG73XDEXt+zs8loFNFDVk+7rMCBRVWv4IT6fshGKyWz72oP8+PVyjh1MpnGHSsR3jMHjyfp31/Gko3w67RmG7v+VysnwapsR1K5a148RG+N/OTnLazvOPUlOCeH0Io/GFAjlY0vQvW9TqjctQ8KkjYx9awH7t2d9YWOhkCI81ekT+lbpzYZg6DuzBxu2rfVjxMbkH9lJKIeA5SIySEQG4tyT5KCIfCgiH/o2PGP8L6RQEG3vqE37++pyZP9JRr4+j/mTNpCWmp7lMje0+hdPR93OhmDliUnXM2bGx6Slnr2GmDEFSXZ2efU603xVHXym+fmZ7fIyZ3P8cDK/j1rNmoTdlCxfmCturUnZKsWzbD9wUn/+u3skxwMCiEpJp1lAdR7s9DFlSmW+t5wxF66cnuUVDFR3X65S1bMXRLoAWEIx2bVxyV5+Hb6KoweTaHBFBZp1rkJQyOk38QLYf2g3Q358nd/2z2JVSArRyencWfERbr76fj9HbYxv5OQ6lNY4Z3ltxLlbYwWgl6rOyvUo/cwSijkXySdTmT1uHct+3UaxUqFccWtNomueuQzLd7M+56M1H3HQA1edrMQjNwwkOrK0nyI2xjdyklAW4NwYa5X7ujowXFUb+yRSP7KEYs7H9jUH+GnIXxzafYJ6l0fR4vrYLEcrAHsPbuXZ73oyx3OA6OQ02gZdwr03vEuxolnvOjMmP8vJWV5Bp5IJgKquBoLO0N6YAq18tXC6921KgzYVWPrrNka+Oo+d6w9l2b5UiWi+uPNXXqlyDxIQzCCZS6/hLRg3xc5pMQVLdkYoA4E04Ft30i2AR1Xv8nFsPmcjFJNT21YdYObglRw9cJL4jjHEd4wh4AzXraSlpzFo5psM2TyC4wHp3B7SgYd6/Bu7K4S5kORkl1cI8BBO6RWA34BPVTUp16P0M0soJjckn0hl1sjVrJqzk3JVi9P2rtoUizhzfa/Nu9fw8ISb2ByYSqfkejx/5xBCgrIu92JMfnJeu7xExAMsVtX3VPV69/F+dpOJe0OuVSKyVkT6eJkfIiIj3flzRSTGnd5URBLdx2IR6ZphmUdFZJmILBeRxzJMLykiP4rIGvdfu8uk8YvgsEDa3lGbdnfVZt+2o4x8dT5rF+w+4zIVS1djWM+Z1EsrwriQZTz7ZSdOJtt1K+bCdsaEoqppwCoRqXiuHbvJ6BOgA1Ab6CEitTM1uxs4oKqxwPvAW+70ZUC8qsYB7YHPRSRQROoC9wJNgQbAtSIS6y7TB5ipqtWAme5rY/ymetOydOvblPCyhZg2YBm/DFtFanJalu2LFIrg616/cnl6BD8W2sLzX3UhKcWSirlwZeegfDjOlfIzRWTCqUc2lmsKrFXV9aqaDIwAOmdq0xnnlGSAMUAbERFVPa6qp/6yQnGqHAPUAuZmmP8rcL2XvgYDXbIRozG5qlipMLo+1YiG7SqyfNY2xryVwP4dWZduCQoM4YPbfqRVekmmF9rE81/eQPIZrsg3Jj/LTkJ5AbgW6A+8m+FxNlHAlgyvt7rTvLZxE8QhnKrGiEgzEVkOLAXud+cvA1qKSISIFAI64lwXA1BGVXe4z3cCXm9sISK9RSRBRBL27NmTjdUw5tx4PAFcckMs1z7SgGOHkhn9xnz+mr0j6/aBQXx42wxapoUzrdB67vuiGe8Ne5H1O/f5MWpjci47CaWjqv6a8YHzRe5TqjpXVesATYBnRSTUvZnXW8B0YCqQiHMGWuZllf+NajLP+0JV41U1PjIy0mfxG1OpTgTd+zaldKVizBy8khmDVpB80vsuLU9gEB/ePoPOnsqsDDvBwJRx3DupJS8OuI2U1Kx3mxmTn2QnobTzMq1DNpbbxv9GDwDRnF6l+O82IhIIFAf+8bPMTSJHgbru669UtbGqtgIOAKvdprtEpJzbVzngzEdFjfGDwiVC6Px4w7/vtTLq9fns2XzEa9vAwGBevXUCv/SczYsVb6akhjIuOJFnBrTj2PHjfo7cmHOXZUIRkQdEZClQQ0SWZHhswNkNdTbzgWoiUtmtBdYdyHzsZQJwqvjkjcBPqqruMoFuHJWAmjilXxCR0u6/FXGOnwzz0lcv4PtsxGiMzwUECE2vq0LnxxqSmpTGmLcSSJyxmaxO2Q8NKcpNV7zA8Dvm0IZofiy0h8cHt2LPvqx3mxmTH2R5HYqIFMc5IP8G/zxj6oiq7s9W5yIdgf8AHpz70r8mIv2BBFWdICKhwBCgIbAf6K6q60XkNvc9U4B0oL+qjnf7/A3nOEsK8ISqznSnRwCjgIrAJuDms8Vp16EYfztxNJmfvvmLjUv2ElO/FG161SK0cNaFJ1SV10bfzcgT86mSlE6niOu4o/OreALtmhWTd3JabdiDc5D77//Fqro5VyPMA5ZQTF5QVZb8vJU/x66lSHgI7XvXI7Ji0TMuM2TGe3yzcSA7g6BGknBb9Ufo3PpeP0VszD/l5Er5h4F+wC6c0QI4x73r53aQ/mYJxeSlnesPMW3AMk4cSeGym2Kp0yrqjCVYklJO8uH4p5h8+GcOeoTuwc15pueXfozYGEdOEspaoJmqFrhzGC2hmLx24mgyMwauYPPy/VRpGMkVt9Y84y4wgB17N/P0d11ZHJLMlcmleev2iYSGFPJTxMbkrNrwFpzrQ4wxuSysSDDXPtSAS66PZePivYx8bR471p35z61cqYp8fceftEspz0/Bu7lr0KWs37zcTxEbk7XsjFC+AmoAk4C/a3ip6nu+Dc33bIRi8pNdGw4z/atlHNmfRLNOlWl0VSUk4MxViN8d+RDfnviV0qnKYzGP0qFtbz9Fay5mORmhbAZ+BIKBohkexphcVKZyMW5+vilVG0UyZ/x6JnyYyLFDZ67D+mS3T3i91nOcEKHflg/47Ovb0XQr3WLyRrbO8gIQkUKqWqCurrIRismPVJWVf+zgt5GrCQoLpN1dtalwllsNb9yzln9N6MEmzwnuoTGP3DH4jO2NyYnzHqGISAsRWQH85b5uICKf+iBGYwwgItS+rDw3PhtPaKFAJnyQyLyJ60lPz/rHX0xkLMNu/ZmqqYX4mgUMGPmEHyM2xpGdXV7/Aa7GLYmiqouBVj6MyRgDRJQvwk3PNqFGs7LMn7SRCR8s4tjBrHeBFQkpwlc9plAxJYjPTkzn2x9e92O0xmQvoaCqWzJNsmp1xvhBUIiHtnfU5srba7Frw2FGvDqPjUv3Ztk+vHAEn13/PeVTAvjPnmF8Pub//Bitudhl67RhEbkEUBEJEpGngJU+jssYk0GtS8px83NNKFw8hEmfLOH3UWtITfH+u658REU+6jiKCqmBfHJ0Mq98dT3pafYb0PhedhLK/Tj3lI/CqQ4c5742xvhReNnC3NinMfUuj2LxT1sY/UYCe7d6r1xcOaomg3r+QlxKCUYFruGpLy7j0KGsRzbG5IZsn+VVENlZXuZCtWnZPn76ZiUnj6fQ7LoqxLWrSICXa1ZSU1N4enh3ZqSvpv5JeKHNQGrGnnZyjjHnJCfXoWTsZGHuhWSMOV+V6kbQ/cWmxNQrxexx6/ju3wu83mo4MDCI928bS++SnfkrWHn4115MmvV1HkRsLgbnNEIRkUWq2tCH8fiVjVDMhU5VWZuwm1kjVpOSlEaTa2OIa1cRj+f034ozF4zl9cSXOOCB9ikVeazLAEpHZr4rtzFnlysjFJzyK8aYfEJEqNakDD1eakZM/QjmjF/PqNfme60H1qbxDXzVYSyNUkowMXgLvb5vx1dDHuTIkcN5ELkpiLJTy6swcEJV00WkOs7dE6eoaoo/AvQlG6GYgmbD4j3MGrGaoweSqN2yPC26VPVavfi7P77ms78+YGdgOnVPphKnDbn0khe4tF7NM5bQNwZyVr5+AdAS5+6Nf+Dc2jdZVW/xRaD+ZAnFFETJJ1OZ98MGlszcQmjRYFreXI3YxqVPSxTJacl8Ov1lftgxiV2eNMqnpBJ/sgb3dP2UylHl8yh6cyHISUJZqKqNROQRIExV3xaRRFWN81GsfmMJxRRkezYf4edv/2LP5iNUqhdBq+7VKRYRdlq7tPQ0flzyDQMWfcbqgBOUS0mnbdhlPHbThwQHh+RB5Ca/y8kxFBGRFsAt/O8Yiiebb9peRFaJyFoR6eNlfoiIjHTnzxWRGHd6UxFJdB+LRaRrhmUeF5HlIrJMRIa796VHRAaJyIYMy8VlJ0ZjCqrIikW58ZnGXHpjLNtWH2T4y3NZNH0zaWn/rEbsCfDQPu5Oxtwxl9drPESYBjIk9U9uGdiESbNGczFfWmDOTXZGKJcDTwJ/qOpbIlIFeExV/3WW5TzAaqAdsBVnV1kPVV2Roc2DQH1VvV9EugNdVbWbiBTC2a2WKiLlgMVAeZz72v8O1FbVEyIyCpisqoNEZBDwg6qOye7K2wjFXCyO7D/JrBGr2bhkLxHRRbji1pqUiSnmtW16Whqffv8MQw9OJU2Uq49V4fbOA6hWoayfozb51XmPUFT1V1Xt5CaTAGDv2ZKJqymwVlXXq2oyMALonKlNZ+BUne0xQBsREVU9rqqp7vRQIGPWCwTCRCQQKARsz0YsxlzUipYMpeMD9ehwXz1OHklm7FsJ/D56DSlJp5dkCfB4ePj6dxh1zRiqU5zxRTfywuQr+WLoiyRnUe7FGMhe+fphIlLMPdtrGbBCRJ7ORt9ROLcPPmWrO81rGzeBHAIi3PdtJiLLgaXA/aqaqqrbgHdwbvq1AzikqtMz9PeaiCwRkfdFxOvOXxHpLSIJIpKwZ8+ebKyGMQWDiFClYSQ9+jWnTssoFs/cwvD+c9m8Yp/X9hXK1GTIHX/Qp3JPtgd5+Ch1HI8NiGde4kw/R24uFNk5hlJbVQ8DXYApQGXgNl8GBaCqc1W1DtAEeFZEQkUkHGdUUxlnF1hhEbnVXeRZnFOamwAlgWey6PcLVY1X1fjIyEhfr4Yx+U5IWCCX96xB16ca4QkMYOKHi5k5eAUnj51+JYCIcEurZ5nc83e6hMYxNyyF/1vwCMMmvpkHkZv8LjsJJUhEgnASygT3+pPsHKXbBlTI8Dranea1jbsLqzjufVdOUdWVwFGgLtAW2KCqe9w4vgMucdvtUEcSMBBnl5sxJgvlY0vQrW8TGrWvxKq5uxj28lzWLtjt9SB8kdDivNJtCP+99CNC1MPb+76l/6BuVsXY/EN2EsrnwEagMDBLRCoB2bm0dj5QTUQqi0gw0B2YkKnNBKCX+/xG4CdVVXeZQAD3/Wq6MWwGmotIIXFOqm+DW0rfPXiPO70Lzu45Y8wZBAZ5aNGlKjf1iadw8WCmDVjGlP8uzfJGXk2qX8HQm2YQl1yE0bKCW79qws8J3/k5apNfnVe1YREJzHDQ/EztOuLc8dEDfK2qr4lIfyBBVSe4p/wOARoC+4HuqrpeRG4D+gApQDrQX1XHu32+DHQDUoFFwD2qmiQiPwGRgACJOMddjp4pPjvLy5j/SU9LJ3HGFub9sAGPR2jWuSp1W5UnwEtdsPS0NN4ccTc/JM3nWIBwaXJJHmrzHnWqWiXji0FOLmwsDrzE/277+yvOF/zpxYIuMJZQjDndwd3H+XXYKrb+dYCIqMK06l6d8tXCvbbdsmMN7016iF8CnZMtmyeHc0vTPlwWd40/QzZ+lpOEMhZn99Gp03tvAxqo6vW5HqWfWUIxxjtVZX3iHv4YvZYj+09StVEkzTtXpUSZQl7bL1zxK4P+eJk/A3eTFCDUOxlIDU916lXoQoum11IuvKif18D4Uk4SymllVqz0ijEXh5TkNBJ/3MzC6ZtJT0mnTsvyxF9TmULFgr22X79lOQNmPM+CtHXscGtS1j+RxmXFr+eem14mKDBbRTZMPpeThDIbeFpVf3dfXwq8o6otfBKpH1lCMSZ7jh1KImHSRpb/vp3AoADi2lYgrl1FgkMDvbZXVdZsn8/3CwYyce/vHPBAgxMebq75MNe1ugsJONc7Z5j8JCcJpQHwDc4pvQAHgF6quiTXo/QzSyjGnJsDO48xd8J61i3cQ1jRIOI7xlCnZRSewKwTxInko3ww/jEmHp3NYU8A1ZOUS0Ia0/3K54mqUN2P0Zvccl4Jxa3H9ZaqPiUixQDcixwLBEsoxpyfXRsOM3vcWratPkjxyDBadK1KlYaRZ7yXyq59W/lqWj9mHZ/HtiCldGoaT1R6lGva3ufHyE1uyMkIZY6qNvdZZHnIEoox509V2bRsH39+t44DO45RtkpxLr0xlrJVip91uYkJw3hvyZucDEjnkYju3NLpBT9FbXJDThLKZzg1t0YDx05NV9UL/momSyjG5Fx6Wjp/zd7J3InrOX4omaoNI2netSolSns/I+yU1duW8+iUnuwKTKNXcEse7vYxHo8dtL8Q5CShDPQyWVX1rtwKLq9YQjEm96QkpZE4wz0jLDWd+ldWIL5jDCFh3g/cA+w6sI2HRl/HqpAUap9ULg1tQ+erX6RS2Qg/Rm7O1XknlILMEooxue/YoSTmfL+ev2bvIKxIEM27VKVWi3JIgPfjK8dPHuWTH55h8qFZ7A2EmifTuC32RTq16e7nyE125WSEMhh4VFUPuq/DgXdthGKMOZPdmw7z28g17Fx/iHKxxWl9S01KliucZfuU1GSG/fYW/904ktD0dB6OepQb2tsB+/woJwllkao2PNu0C5ElFGN8S9OVlbN38OfYtaQkpdGofSUat69EYFDWx0oWr5/Foz8/RJKk83Dk7dxyndc7UZg8lJN7yge4o5JTHZXEuWuiMcackQQItS8tT89+zanaqDQJkzYy4pV5bP1rf5bLNKjSii+vHkrxdA/v7hvC0wOuYvP21X6M2pyv7IxQbgeewznLC+Am4DVVHeLj2HzORijG+NeWFfv5ZfgqDu85QY1mZbnkhtgsy7hs27OBfuN7MTdoP0XSlas99Xjq5i8pHFbEz1GbzHJ0UF5EagNXui9/UtUVuRxfnrCEYoz/pSansWDqJhZO20RQiIfmXapS57LyWR60/znhO75c+DpLQpKoeVJ4tPE7XBZ/lZ+jNhnZWV5eWEIxJu/s33GMWcNXsW31QUrHFKNV9+qUiSmWZfvPJzzHV/smEJaezvXSht63vE9YiO19zwuWULywhGJM3lJVVs/dyR/frePE4WRqXlKOFl2qZrkbbNmG33n6p4fZ7kml7ZFC3HX1AOpUb+DnqI0lFC8soRiTPySfSCVh8kYW/7QFT1AATa+tTL0rovF4uVvk8aSj9B3Xix+TVlM6NY0binXk/uvfIsCusvcbSyheWEIxJn85uOs4v49ew6Zl+wgvW4iWN1enQu2SXtv+unQcb899ic1BSvWkADqU7cwdHV8gMDDIz1FffHJy2nBO3rS9iKwSkbUi0sfL/BARGenOnysiMe70piKS6D4Wi0jXDMs8LiLLRWSZiAx370uPiFR2+1jr9ul9zGyMybdKlCnEtQ834JoH65OWpkz4MJGpXyzlyP6Tp7W9vF5Xxt4+l1uCmnI4II0PDozjukEN+WDkwxw/ccxL78bXfDZCcUvfrwbaAVuB+UCPjGeIiciDQH1VvV9EugNdVbWbiBQCklU1VUTKAYuB8kAZ4HegtqqeEJFRwGRVHeQ+/05VR4jIf4HFqvrZmWK0EYox+VdqShqJP25hwZSNINDkmso0aFPB671XTiYd56tJLzF131Q2BkPl5HSuDm3NLde9RokSJfwee0Hn911eItIC6KeqV7uvnwVQ1TcytJnmtpktIoHATiBSMwQlIpWBOTgVj8u4zxsAh4HxwIfAj8AeoKybhP7x3lmxhGJM/nd47wl+H72GDYv3UrJ8YVr3rEG52BJe26alpfL11FcZtfM7dgYqUSmp1EotRXyFa7mh7SOEhpy5ArLJnrzY5RUFbMnweqs7zWsbVU0FDgERACLSTESWA0uB+1U1VVW3Ae8Am4EdwCFVne4uc9DtI6v3wu23t4gkiEjCnj17cmE1jTG+VKxUGB0fqM81D9Yn+WQq372zkJ+HrOTksZTT2no8gdx7TT8m35HAo1HdiZBwZoUc4M2933Lr4BZs2bEmD9bg4pFvb+ysqnNVtQ7QBHhWRELdEjCdgco4u8AKi8it59jvF6oar6rxkZGRuR+4McYnYuqXoudLzYlrV5GVs3cyrN8c1iTswtteliBPMPe0fZ6hd//JTzf9yh2hLVkfnMYDP1zPivW2V8JXfJlQtgEVMryOdqd5bePu8ioO7MvYQFVXAkeBukBbYIOq7lHVFOA74BJ3mRJuH1m9lzHmAhcU4uHSG2K56dl4ipYMZfqXy5n06RIO7z2R5TLFi0TwZLdP+b/yd7MnMJ1//dSL2Uum+THqi4cvE8p8oJp79lUw0B2YkKnNBKCX+/xGnLIu6i4TCCAilYCawEacXV3NRaSQODevbgOsdI+5/Oz2gdvn975bNWNMXoqsUJQbnonnspuqsW31QYa/PJeEKRtJS0nPcpnuVz3OyzX6cDIAHl/wBO8Pe4j0tKzbm3Pn0+tQRKQj8B/AA3ytqq+JSH8gQVUnuKf8DgEaAvuB7qq6XkRuA/oAKUA60F9Vx7t9vgx0A1KBRcA9qpokIlWAEUBJd/qtqpp0pvjsoLwxF74j+0/yx+g1rFu0hxJlCtGqW9bXrgAkrvqNV3/9F6tCUmlxPISHrvicBjUb+zHiC59d2OiFJRRjCo5Ny/Yxa+RqDu85QZW4SC69MZZipcK8tk1JTeK10XcxPmkxYelKsxNhNIloxzXtHqNERBk/R37hsYTihSUUYwqW1JQ0Emc4166oQqOrKtLo6koEBnsvyzJnxRQGznufBbqdpAChVlIqt0bfR6eOj/k38AuMJRQvLKEYUzAd2X+SP79by9qE3RQtGcqlN8ZSpWEkzqFXL+2TDvPNbx8xfPMIjgUo16ZUpM8tIyhcKOvqxxczSyheWEIxpmDbtvoAv41czb5tx4iuGU6r7tUJL5v1fe13HdrOc6N7MC9oP9EpSs30KKqVaknr+F7Urlghy+UuNpZQvLCEYkzBl56WzrJZ25k7YT2pyWnEtatIfIcYgkKyrk48YMKLzNg5kdXBKaSKUCwtnc6BV/B4zw8ICrSqxpZQvLCEYszF4/jhZGZ/t5a/5uykcIkQWnSpQvWmZbO8UyTAsWN7+ClhCAPXfMOaoDRaHgvliau/JrZqPT9Gnv9YQvHCEooxF58daw/y++g17N50hNKVinLpjdUoX63EGZdJSU2i/+g7+D5pKWVS02mcUppmsTdybeveBAVdfIXNLaF4YQnFmIuTpiur5+1k9vj1HDuYRJW4SFp0rUqJMmcuHjk9cSwDFrzDGs8R0kQonZpOy8B69O74FuUjK/kp+rxnCcULSyjGXNxSktNYPGMLC6dtIi0lnTqtoojvGJPlLYhP2X1oO6Nmvs8fe2ewLCSVwunptEyvxFNdBlAmwmtd2gLFEooXllCMMeAcX5k3cT0r/thBYFAADa+qSFzbimc8cH/KtNlDGbX0YxKCj1A2FZ6s8zxXtejhh6jzjiUULyyhGGMyOrDzGHPGr2d94h7CigXTpGMMtVuW93pv+8zGzPyYTzZ+xiGPcENgPM90/4rAAnpGmCUULyyhGGO82bn+ELPHrWP7moMUiwyjWafKxDYuQ8AZzggD2LDtL1764VYWhSZR86RwWdFbuabNA8SWKeqnyP3DEooXllCMMVlRVTYt28ec8evZt+0o4WUL0eSaylRtXPqMiSU9LY0Pxz3KmMO/cCQAWh4OIqrI3dzXrTclCxeMM8IsoXhhCcUYczaarqxbtIf5kzawf/sxwssWotHVlajWtMwZd4UdPr6XD6Y+wtjDSxGg0bEgLo/pxa3tHyHAc2HvCrOE4oUlFGNMdp1KLAmTN7Jv21GKlAyhYbuK1Lqk/BkP3m/dv5avf3qBKUeWcjRAqJYktC/TiTs7vnjBXsNiCcULSyjGmHN1alfYwqmb2LHuECGFAqnTMop6raMpEh6S5XJHju3jk+//j5+Oz2VHkBCVotSTSsSUqE2DKpfTrN7VBAUG+XFNzp8lFC8soRhjcmLH2oMsnrmF9Yl7EBGqNIyk7uVRlK9WIsvKxknJJ/n6h5eYsXcq64LTSHPblUpNp35qFI0rdqPz5bdRvFD+Hb1YQvHCEooxJjcc3nuCJb9s5a8/d5B0PJWS5QtT/4poajQvS2BQ1rvDjh4/zNxl01m84RcWH5rHkuDjpIrQ6HgI/+7+I6XDw/24FtlnCcULSyjGmNyUkpzG2oRdLPl5K3u3HCWsaBD1WkdT9/IowoqcfcSx/8AGPpvahxHJK2h2PIz/9PqZIoWyLrefV7JKKGe/Widnb9peRFaJyFoR6eNlfoiIjHTnzxWRGHd6UxFJdB+LRaSrO71GhumJInJYRB5z5/UTkW0Z5nX05boZY0xmQcEeal1Snpufa0Lnx+IoXakY8yZu4Jtn/+SXYas4uOv4GZcvGV6Z53uMpEdoI+YWOkGfwe1ITk7yU/Q557MRioh4gNVAO2ArMB/ooaorMrR5EKivqveLSHegq6p2E5FCQLKqpopIOWAxUF5VUzP1vw1opqqbRKQfcFRV38lujDZCMcb42v7tx1g8czOr5u4iLS2dyvVL0bBdRcrFljjjcn2+vYlJaX9R/wREaGHCPEUoFRbN07cN8kvcZ5LVCCXQh+/ZFFirquvdAEYAnYEVGdp0Bvq5z8cAH4uIqGrGNB4KeMt6bYB1qroptwM3xpjcUrJ8Ya64rRbNOldl6S9bWfrrVjYs3kvZKsVo3D6GSvUivB7Af+OWUQQMu5WFgcvZFHCMowFHqXByF0/nwTpkly8TShSwJcPrrUCzrNq4o5FDQASwV0SaAV8DlYDbMo5OXN2B4ZmmPSwitwMJwJOqeiBzUCLSG+gNULFixfNZL2OMOWeFigXTrFMVGl1diZV/7iBxxmYmfbqE0pWK0uTaylSq+8/EIiK8fsvQv1+nazrHk47lRejZ5tNjKDmhqnNVtQ7QBHhWREJPzRORYKATMDrDIp8BVYE4YAfwbhb9fqGq8aoaHxkZ6avwjTHGq6AQD/WviOaW/s254raanDiawqRPljD27QVsX3Pab+C/BUgARULzd00wXyaUbUCFDK+j3Wle24hIIFAc2JexgaquBI4CdTNM7gAsVNVdGdrtUtU0VU0HBuDscjPGmHzJ4wmg9qXluaV/c1rfUoOj+08y7t1F/PDJYvZtO5rX4Z0XXyaU+UA1Eansjii6AxMytZkA9HKf3wj8pKrqLhMIICKVgJrAxgzL9SDT7i734P0pXYFlubUixhjjKx5PAHVaRnHLKy1o0bUqO9cdYuSr8/h5yEqOHbpwzvACHx5DcY+JPAxMAzzA16q6XET6AwmqOgH4ChgiImuB/ThJB+AyoI+IpADpwIOquhdARArjnDl2X6a3fFtE4nAO4G/0Mt8YY/KtoGAPja6uRO3LypMweSNLf9nK6oTdNLqqIg3bVSQwOP8XlLQLG+20YWNMPnRoz3Fmf7eOdYv2UDQilMtuqkblBqWyLOniT3lyYaMxxpjzUzyyEO3vq0fnx+IICvEw5b9L+eGjxRzcfeaLI/OSJRRjjMnHomuW5Obnm3DZTdXYsf4QI/rPY94PG0hNScvr0E7jy+tQjDHG5AKPJ4AGbSoQG1+aP0avYf4PG1g1dyetulenUp2IvA7vbzZCMcaYC0Th4iFcdU9dOj0aR0CA8MNHi5ny+VKO7D+Z16EBllCMMeaCU6FWSbr3bUqzzlXYvGwfw/rNYcHUjaSlpudpXLbLyxhjLkCeoADiO8RQvUkZfh+9hjnj1/PX7J207FaNirXzZjeYjVCMMeYCVqxUGB0fqM+1jzRA05WJHy5m+pfLOH442e+x2AjFGGMKgEp1Ioh+sRkLpm1iwdSNbF6xnxZdq1L70vJIgH+uXbERijHGFBCeoACaXluZ7n2bUiq6CL8MXcWYtxLYuf6QX97fEooxxhQw4WUL0/nxhrS9szZHDyYx9u0FzBi0gqMHfFsbzHZ5GWNMASQi1GhWlsoNSrFgyiYSZ25m3YLdxLWrSMOrKhIcmvtf/1bLy2p5GWMuAof3nmDO+HWsSdhNWNEgrrqnLtE1ws+rr7y4BbAxxph8olipMK66py4N2hxm3sT1lChdKNffwxKKMcZcRMpULsZ1/4rzSd92UN4YY0yusIRijDEmV1hCMcYYkyssoRhjjMkVPk0oItJeRFaJyFoR6eNlfoiIjHTnzxWRGHd6UxFJdB+LRaSrO71GhumJInJYRB5z55UUkR9FZI377/mdD2eMMea8+CyhiIgH+AToANQGeohI7UzN7gYOqGos8D7wljt9GRCvqnFAe+BzEQlU1VWqGudObwwcB8a5y/QBZqpqNWCm+9oYY4yf+HKE0hRYq6rrVTUZGAF0ztSmMzDYfT4GaCMioqrHVTXVnR4KeLv6sg2wTlU3eelrMNAld1bDGGNMdvgyoUQBWzK83upO89rGTSCHgAgAEWkmIsuBpcD9GRLMKd2B4Rlel1HVHe7znUAZb0GJSG8RSRCRhD179pz7WhljjPEq317YqKpzgToiUgsYLCJTVPUkgIgEA52AZ7NYVkXEa00ZVf0C+MLtZ4+IbPLWLgulgL3n0L6guBjX+2JcZ7g41/tiXGfI2XpX8jbRlwllG1Ahw+tod5q3NltFJBAoDuzL2EBVV4rIUaAucKrwVgdgoaruytB0l4iUU9UdIlIO2H22AFU18lxWSEQSvNWvKeguxvW+GNcZLs71vhjXGXyz3r7c5TUfqCYild0RRXdgQqY2E4Be7vMbgZ/c0UVlN8EgIpWAmsDGDMv14J+7uzL31Qv4PrdWxBhjzNn5bISiqqki8jAwDfAAX6vqchHpDySo6gTgK2CIiKwF9uMkHYDLgD4ikgKkAw+q6l4AESkMtAPuy/SWbwKjRORuYBNws6/WzRhjzOku6vL150pEervHYC4qF+N6X4zrDBfnel+M6wy+WW9LKMYYY3KFlV4xxhiTKyyhGGOMyRWWULLpbHXJCgIRqSAiP4vIChFZLiKPutMLfJ00EfGIyCIR+cF9XdmtL7fWrTcXnNcx5jYRKSEiY0TkLxFZKSItCvq2FpHH3f/by0RkuIiEFsRtLSJfi8huEVmWYZrXbSuOD931XyIijc73fS2hZEM265IVBKnAk6paG2gOPOSu58VQJ+1RYGWG128B77t15g7g1J0raD4ApqpqTaABzvoX2G0tIlHAv3DqBNbFOfu0OwVzWw/CqYOYUVbbtgNQzX30Bj473ze1hJI92alLdsFT1R2qutB9fgTnCyaKAl4nTUSigWuAL93XAlyJU18OCuY6Fwda4Zy6j6omq+pBCvi2xrlUIsy9zq0QsIMCuK1VdRbOpRgZZbVtOwPfqGMOUMK9OPycWULJnuzUJStQxLmVQENgLtmsk3YB+w/wfzjXPIFTT+5ghvpxBXF7Vwb2AAPdXX1futd4FdhtrarbgHeAzTiJ5BCwgIK/rU/Jatvm2vebJRRzGhEpAowFHlPVwxnnqXOeeYE511xErgV2q+qCvI7FzwKBRsBnqtoQOEam3VsFcFuH4/warwyUBwpz+m6hi4Kvtq0llOzJTl2yAkFEgnCSyVBV/c6dvOvUEDi7ddIuIJcCnURkI86uzCtxji2UOFX+h4K5vbcCW90irODs8mlEwd7WbYENqrpHVVOA73C2f0Hf1qdktW1z7fvNEkr2ZKcu2QXPPXbwFbBSVd/LMKvA1klT1WdVNVpVY3C260+qegvwM059OShg6wygqjuBLSJSw53UBlhBAd7WOLu6motIIff/+ql1LtDbOoOstu0E4Hb3bK/mwKEMu8bOiV0pn00i0hFnX/upumSv5W1EuU9ELgN+w7kHzanjCc/hHEcZBVTErZOmqpkP+F3wRKQ18JSqXisiVXBGLCWBRcCtqpqUh+HlOhGJwzkRIRhYD9yJ8yOzwG5rEXkZ6IZzRuMi4B6c4wUFaluLyHCgNU6J+l3AS8B4vGxbN7l+jLP77zhwp6omeOn27O9rCcUYY0xusF1exhhjcoUlFGOMMbnCEooxxphcYQnFGGNMrrCEYowxJldYQjEmF4jIn+6/MSLSM5f7fs7bexmT39hpw8bkoozXspzDMoEZakl5m39UVYvkQnjG+JSNUIzJBSJy1H36JtBSRBLde294ROTfIjLfvdfEfW771iLym4hMwLlaGxEZLyIL3Pt19HanvYlTHTdRRIZmfC/3yuZ/u/f2WCoi3TL0/UuGe50MdS9eM8anAs/exBhzDvqQYYTiJoZDqtpEREKAP0Rkutu2EVBXVTe4r+9yr1wOA+aLyFhV7SMiD6tqnJf3uh6Iw7mXSSl3mVnuvIZAHWA78AdOzarfc3tljcnIRijG+NZVOHWSEnFK2ETg3MgIYF6GZALwLxFZDMzBKdZXjTO7DBiuqmmqugv4FWiSoe+tqpoOJAIxubAuxpyRjVCM8S0BHlHVaf+Y6BxrOZbpdVughaoeF5FfgNAcvG/GWlRp2N+68QMboRiTu44ARTO8ngY84N4WABGp7t7IKrPiwAE3mdTEuQXzKSmnls/kN6Cbe5wmEucOjPNyZS2MOQ/2q8WY3LUESHN3XQ3CubdKDLDQPTC+B++3mJ0K3C8iK4FVOLu9TvkCWCIiC93S+qeMA1oAi3FulvR/qrrTTUjG+J2dNmyMMSZX2C4vY4wxucISijHGmFxhCcUYY0yusIRijDEmV1hCMcYYkyssoRhjjMkVllCMMcbkiv8HOEB2xqH68QkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    plt.plot(range(1,its[i]+1), loss[i], label=f'lr = {lrs[i]}')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('cross-entropy loss')\n",
    "plt.title('Effect of learning rate on training loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('learning_rate.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Task 2"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "989a8ee0261a415be34d4cf0f45e98134ff6fbcaa2e29b3efcaef888d322ba01"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
