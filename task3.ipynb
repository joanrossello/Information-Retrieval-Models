{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "import string\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(text):\n",
    "    '''\n",
    "    Function that normalises text and returns tokens.\n",
    "    Input: text --> text string we want to tokenise\n",
    "    Output: tokens --> list of tokens taken from the text string\n",
    "    '''\n",
    "\n",
    "    text = text.lower() # convert all to lower case\n",
    "    text = contractions.fix(text) # expand contractions\n",
    "    # text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "    tokens = text.split()\n",
    "    # tokens = re.findall(r'(\\b[a-z|1-9|\\S]+\\b)', text) # tokenisation\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_words] # remove stop words\n",
    "    filtered_tokens = list(map(lemmatizer.lemmatize, filtered_tokens)) # lemmatization of nouns\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inverted_index.pkl', 'rb') as f:\n",
    "    inv_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = pd.read_csv('candidate-passages-top1000.tsv', delimiter='\\t', header=None, names=['qid','pid','query','passage'])\n",
    "tq = pd.read_csv('test-queries.tsv', delimiter='\\t', header=None, names=['qid','query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = cp[['pid', 'passage']].copy()\n",
    "passages = passages.drop_duplicates()\n",
    "passages = passages.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF·IDF passages\n",
    "p_tfidf = {i:{} for i in passages['pid']}\n",
    "\n",
    "# Also calculate the length of passages which will be useful in BM25\n",
    "len_passages = {}\n",
    "\n",
    "def p_tfidf_func(row):\n",
    "    pid = row['pid']\n",
    "    passage = row['passage']\n",
    "    check = normalise(passage)\n",
    "    len_passages[pid] = len(check)\n",
    "    unique_words = list(set(check))\n",
    "\n",
    "    for item in unique_words:\n",
    "        tf = inv_index[item][pid] / len(check) # Normalise the frequency from inverted index\n",
    "        idf = np.log(N/len(inv_index[item]))\n",
    "        p_tfidf[pid][item] = tf*idf\n",
    "    p_tfidf[pid]['norm_of_passage'] = np.linalg.norm(np.array(list(map(p_tfidf[pid].get, p_tfidf[pid].keys())))) # add norm of the passage\n",
    "\n",
    "_ = passages.apply(lambda row: p_tfidf_func(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF·IDF queries\n",
    "q_tfidf = {i:{} for i in tq['qid']}\n",
    "\n",
    "def q_tfidf_func(row):\n",
    "    qid = row['qid']\n",
    "    query = row['query']\n",
    "    check = normalise(query)\n",
    "    unique_words = list(set(check))\n",
    "\n",
    "    for item in unique_words:\n",
    "        if item in inv_index.keys():\n",
    "            tf = check.count(item) / len(check)\n",
    "            idf = np.log(N/len(inv_index[item]))\n",
    "            q_tfidf[qid][item] = tf*idf\n",
    "    q_tfidf[qid]['norm_of_query'] = np.linalg.norm(np.array(list(map(q_tfidf[qid].get, q_tfidf[qid].keys())))) # add norm of the query\n",
    "\n",
    "_ = tq.apply(lambda row: q_tfidf_func(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the cosine similarity\n",
    "def cosine_sim(query,passage):\n",
    "    '''\n",
    "    This function computes the cosine similarityu between queries and passages.\n",
    "    Inputs\n",
    "    query: dictionary with tf·idf vector representation of the query\n",
    "    passage: dictionary with tf·idf vector representation of the passage\n",
    "    Note that we only include the matchin words in the vector representation.\n",
    "\n",
    "    Output\n",
    "    score: cosine similarity score\n",
    "    '''\n",
    "\n",
    "    qk = query.keys()\n",
    "    pk = passage.keys()\n",
    "\n",
    "    common = set(qk) & set(pk)\n",
    "\n",
    "    q = np.array(list(map(query.get, common)))\n",
    "    p = np.array(list(map(passage.get, common)))\n",
    "\n",
    "    dot_product = np.dot(q, p)\n",
    "    norm_q = query['norm_of_query']\n",
    "    norm_p = passage['norm_of_passage']\n",
    "    \n",
    "    score =  dot_product / (norm_q * norm_p)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- ----- ----- ----- start of trials ----- ----- ----- -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09719924458147798"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For every query check its candidate passages and compute the cosine similarity score with each of them. \n",
    "# Store the top 100 passages in descending order of cosine similarity score.\n",
    "\n",
    "query = q_tfidf[cp['qid'][0]]\n",
    "passage = p_tfidf[cp['pid'][0]]\n",
    "\n",
    "cosine_sim(query,passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'definition': 1.5252624976411717, 'sensibilities': 3.3836140219225803}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'examples': 0.6299215470745732,\n",
       " 'molecules': 0.6633000788578378,\n",
       " 'definition': 0.5719734366154394,\n",
       " 'along': 0.5428558518056267,\n",
       " 'rna': 2.045622209625479,\n",
       " 'types': 0.4526793844644295}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = 1.5252624976411717*0.5719734366154394\n",
    "norm1 = np.sqrt(1.5252624976411717**2 + 3.3836140219225803**2)\n",
    "norm2 = np.sqrt(0.6299215470745732**2 + 0.6633000788578378**2 + 0.5719734366154394**2 + 0.5428558518056267**2 + 2.045622209625479**2 + 0.4526793844644295**2)\n",
    "\n",
    "dot / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th>query</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1108939</td>\n",
       "      <td>8406305</td>\n",
       "      <td>what slows down the flow of blood</td>\n",
       "      <td>In a study, high cholesterol raised men's risk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1108939</td>\n",
       "      <td>7144974</td>\n",
       "      <td>what slows down the flow of blood</td>\n",
       "      <td>What is a transient ischemic attack? A transie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>1108939</td>\n",
       "      <td>5163859</td>\n",
       "      <td>what slows down the flow of blood</td>\n",
       "      <td>For gas exchange to occur in the lungs and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>1108939</td>\n",
       "      <td>8037119</td>\n",
       "      <td>what slows down the flow of blood</td>\n",
       "      <td>A transient ischemic attack (TIA) is a brief e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>1108939</td>\n",
       "      <td>5182924</td>\n",
       "      <td>what slows down the flow of blood</td>\n",
       "      <td>In gastroparesis, motility slows down, so some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188151</th>\n",
       "      <td>1108939</td>\n",
       "      <td>8330715</td>\n",
       "      <td>what slows down the flow of blood</td>\n",
       "      <td>2. Foods for healthy blood flow. A healthy blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188457</th>\n",
       "      <td>1108939</td>\n",
       "      <td>7911117</td>\n",
       "      <td>what slows down the flow of blood</td>\n",
       "      <td>Tumors that start in the bone or that spread t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189697</th>\n",
       "      <td>1108939</td>\n",
       "      <td>841371</td>\n",
       "      <td>what slows down the flow of blood</td>\n",
       "      <td>This is the flow of electrons round the circui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189789</th>\n",
       "      <td>1108939</td>\n",
       "      <td>8418428</td>\n",
       "      <td>what slows down the flow of blood</td>\n",
       "      <td>If your numbers are not in the normal range, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189790</th>\n",
       "      <td>1108939</td>\n",
       "      <td>8418430</td>\n",
       "      <td>what slows down the flow of blood</td>\n",
       "      <td>Blood Urea Nitrogen (BUN): Urea nitrogen is a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            qid      pid                              query  \\\n",
       "125     1108939  8406305  what slows down the flow of blood   \n",
       "285     1108939  7144974  what slows down the flow of blood   \n",
       "444     1108939  5163859  what slows down the flow of blood   \n",
       "928     1108939  8037119  what slows down the flow of blood   \n",
       "956     1108939  5182924  what slows down the flow of blood   \n",
       "...         ...      ...                                ...   \n",
       "188151  1108939  8330715  what slows down the flow of blood   \n",
       "188457  1108939  7911117  what slows down the flow of blood   \n",
       "189697  1108939   841371  what slows down the flow of blood   \n",
       "189789  1108939  8418428  what slows down the flow of blood   \n",
       "189790  1108939  8418430  what slows down the flow of blood   \n",
       "\n",
       "                                                  passage  \n",
       "125     In a study, high cholesterol raised men's risk...  \n",
       "285     What is a transient ischemic attack? A transie...  \n",
       "444     For gas exchange to occur in the lungs and the...  \n",
       "928     A transient ischemic attack (TIA) is a brief e...  \n",
       "956     In gastroparesis, motility slows down, so some...  \n",
       "...                                                   ...  \n",
       "188151  2. Foods for healthy blood flow. A healthy blo...  \n",
       "188457  Tumors that start in the bone or that spread t...  \n",
       "189697  This is the flow of electrons round the circui...  \n",
       "189789  If your numbers are not in the normal range, a...  \n",
       "189790  Blood Urea Nitrogen (BUN): Urea nitrogen is a ...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.loc[cp['qid'] == tq['qid'][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- ----- ----- ----- end of trials ----- ----- ----- -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores = np.array([[0,0,0]])\n",
    "\n",
    "for k in range(len(tq)):\n",
    "    scores = []\n",
    "    qid = tq['qid'][k]\n",
    "\n",
    "    for pid in cp.loc[cp['qid'] == tq['qid'][k]]['pid']:\n",
    "\n",
    "        query = q_tfidf[qid]\n",
    "        passage = p_tfidf[pid]\n",
    "\n",
    "        score = cosine_sim(query,passage)\n",
    "\n",
    "        scores.append([qid,pid,score])\n",
    "    \n",
    "    scores = np.array(scores, dtype=\"O\")\n",
    "    scores = scores[np.argsort(-scores[:,-1])] # sort in descending order\n",
    "    \n",
    "    final_scores = np.append(final_scores, scores[:100,:], axis=0)\n",
    "\n",
    "final_scores = final_scores[1:,:] # remove the [0,0,0] row we used to initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(array).to_csv(\"np_array.csv\", header=['qid','pid','score'])\n",
    "pd.DataFrame(final_scores).to_csv(\"tfidf.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, and keeping things separate, we compute the frequencies of the query terms separately\n",
    "qf_dict = {i:{} for i in tq['qid']}\n",
    "\n",
    "def qf_func(row):\n",
    "    qid = row['qid']\n",
    "    query = row['query']\n",
    "    check = normalise(query)\n",
    "    unique_words = list(set(check))\n",
    "\n",
    "    for item in unique_words:\n",
    "        if item in inv_index.keys():\n",
    "            qf_dict[qid][item] = check.count(item) # non-normalised frequency\n",
    "\n",
    "_ = tq.apply(lambda row: qf_func(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(n, N, k1, k2, b, dl, avdl, f, qf, r=0, R=0):\n",
    "    '''\n",
    "    BM25 score calculating function\n",
    "\n",
    "    Inputs\n",
    "    n: (vector of integers) number of total docs. containing each term in the query (each vector element corresponds to a term)\n",
    "    N: (integer) total number of documents we have\n",
    "    k1: (scalar) constant parameter set empirically\n",
    "    k2: (scalar) constant parameter set empirically\n",
    "    b: (scalar) constant parameter set empirically\n",
    "    dl: (integer) document length --> number of tokens\n",
    "    avdl: (scalar) average document length --> average number of tokens in the set of documents\n",
    "    f: (vector of integers) frequency in the document of each term in the query (each vector element corresponds to a term)\n",
    "    qf: (vector of integers) frequency in the document of each term in the query (each vector element corresponds to a term)\n",
    "    r: (vector of integers) number of relevant docs. containing each term in the query (each vector element corresponds to a term)\n",
    "    R: (integer) total number of relevant documents\n",
    "\n",
    "    Note that if we do not have information about relevance feedback, r and R are set to 0\n",
    "\n",
    "    Output\n",
    "    score: (scalar) BM25 score of a document with respect to a query\n",
    "\n",
    "    '''\n",
    "\n",
    "    K = k1 * ((1 - b) + b * (dl/avdl))\n",
    "\n",
    "    score = np.sum( np.log( ((r+0.5)/(R-r+0.5)) / ((n-r+0.5)/(N-n-R+r*0.5)) ) * (((k1+1)*f)/(K+f)) * (((k2+1)*qf)/(k2+qf)) )\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- trials ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.625185296994648"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "# qf = np.array([1,1])\n",
    "# f = np.array([15, 25])\n",
    "# n = np.array([40000, 300])\n",
    "# Nt = 500000\n",
    "# dl = 0.9\n",
    "# avdl = 1\n",
    "# k1 = 1.2\n",
    "# k2 = 100\n",
    "# b = 0.75\n",
    "\n",
    "# BM25(n,Nt,k1,k2,b,dl,avdl,f,qf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- end of trials ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(passages)\n",
    "k1 = 1.2\n",
    "k2 = 100\n",
    "b = 0.75\n",
    "avdl = sum(len_passages.values()) / len(len_passages)\n",
    "\n",
    "BM25_scores = np.array([[0,0,0]])\n",
    "\n",
    "for k in range(len(tq)):\n",
    "    scores = []\n",
    "    qid = tq['qid'][k]\n",
    "    query = qf_dict[qid]\n",
    "    query_words = query.keys()\n",
    "\n",
    "    for pid in cp.loc[cp['qid'] == tq['qid'][k]]['pid']:\n",
    "        \n",
    "        passage = p_tfidf[pid]\n",
    "        passage_words = passage.keys()\n",
    "\n",
    "        common = list(set(query_words) & set(passage_words))\n",
    "\n",
    "        dl = len_passages[pid]\n",
    "\n",
    "        n, f, qf = np.zeros(len(common)), np.zeros(len(common)), np.zeros(len(common))\n",
    "        for i in range(len(common)):\n",
    "            n[i] = len(inv_index[common[i]])\n",
    "            f[i] = inv_index[common[i]][pid]\n",
    "            qf[i] = qf_dict[qid][common[i]]\n",
    "\n",
    "        score = BM25(n,N,k1,k2,b,dl,avdl,f,qf)\n",
    "\n",
    "        scores.append([qid,pid,score])\n",
    "    \n",
    "    scores = np.array(scores, dtype=\"O\")\n",
    "    scores = scores[np.argsort(-scores[:,-1])] # sort in descending order\n",
    "    \n",
    "    BM25_scores = np.append(BM25_scores, scores[:100,:], axis=0)\n",
    "\n",
    "BM25_scores = BM25_scores[1:,:] # remove the [0,0,0] row we used to initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(BM25_scores).to_csv(\"bm25.csv\", header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "989a8ee0261a415be34d4cf0f45e98134ff6fbcaa2e29b3efcaef888d322ba01"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
